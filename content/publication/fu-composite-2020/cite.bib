@inproceedings{fu_composite_2020,
 abstract = {This paper proposes an approach for speech emotion recognition based on the composite feature extraction. The traditional paralinguistic and prosodic features and the neurogram features are extracted and concatenated together to be the composite feature. The neural feature is presented by a computational model which outputs a series of responses of a speech's particular characteristic frequency through auditory nerve fiber. The exported responses signals are visualized as the 2D neurogram and then extracted as neural feature. With the extracted composite feature, support vector machines is used to classify the emotion. The eNTERFACE database is used and the various metrics are calculated to evaluate the performance of the proposed approach. Experimental results show that the proposed approach achieves good performances under different conditions and performs better than the related work in terms of the various evaluation metrics.},
 author = {Fu, Yangzhi and Yuan, Xiaochen},
 booktitle = {2020 IEEE 23rd International Conference on Computational Science and Engineering (CSE)},
 doi = {10.1109/CSE50738.2020.00018},
 file = {Fu_Yuan_2020_Composite Feature Extraction for Speech Emotion Recognition.pdf:/Users/maodou/Zotero/storage/AILWLVA3/Fu_Yuan_2020_Composite Feature Extraction for Speech Emotion Recognition.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/KWTX8FE5/9345919.html:text/html},
 keywords = {Feature extraction, Visualization, Databases, Composite Feature Extraction, Emotion recognition, Neurogram Features, Noise measurement, Paralinguistic and Prosodic Features, Speech Emotion Classification, Speech recognition, Support Vector Machine, Two dimensional displays},
 month = {December},
 pages = {72--77},
 title = {Composite Feature Extraction for Speech Emotion Recognition},
 year = {2020}
}
