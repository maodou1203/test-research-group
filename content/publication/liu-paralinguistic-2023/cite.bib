@article{liu_paralinguistic_2023,
 abstract = {Abstract
Emotion plays a dominant role in speech. The same utterance with different emotions can lead to a completely different meaning. The ability to perform various of emotion during speaking is also one of the typical characters of human. In this case, technology trends to develop advanced speech emotion classification algorithms in the demand of enhancing the interaction between computer and human beings. This paper proposes a speech emotion classification approach based on the paralinguistic and spectral features extraction. The Mel-frequency cepstral coefficients (MFCC) are extracted as spectral feature, and openSMILE is employed to extract the paralinguistic feature. The machine learning techniques multi-layer perceptron classifier and support vector machines are respectively applied into the extracted features for the classification of the speech emotions. We have conducted experiments on the Berlin database to evaluate the performance of the proposed approach. Experimental results show that the proposed approach achieves satisfied performances. Comparisons are conducted in clean condition and noisy condition respectively, and the results indicate better performance of the proposed scheme.},
 author = {Liu, Tong and Yuan, Xiaochen},
 doi = {10.1186/s13636-023-00290-x},
 issn = {1687-4722},
 journal = {EURASIP Journal on Audio, Speech, and Music Processing},
 language = {en},
 month = {May},
 number = {1},
 pages = {23},
 title = {Paralinguistic and spectral feature extraction for speech emotion classification using machine learning techniques},
 url = {https://asmp-eurasipjournals.springeropen.com/articles/10.1186/s13636-023-00290-x},
 urldate = {2024-01-12},
 volume = {2023},
 year = {2023}
}
