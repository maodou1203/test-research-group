
@article{li_dual-tree_2018,
	title = {Dual-{Tree} {Complex} {Wavelet} {Transform} {Based} {Audio} {Watermarking} {Using} {Distortion}-{Compensated} {Dither} {Modulation}},
	volume = {6},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2018.2876233},
	abstract = {This paper presents a local audio watermarking method based on the dual-tree complex wavelet transform (DT CWT) and distortion-compensated dither modulation (DC-DM). Specifically, we perform DT CWT on extracted audio segment, and embed the watermark signal in the decomposed low-pass coefficients. During the embedding process, the selected coefficients are block-divided into multiple host vectors, and the watermark signal is embedded into the selected set of host vectors by the dither modulation process. During the extraction process, the DC-DM is applied to generate the statistical differences, and the minimum distance decoding is employed to extract the watermark signal. Experimental results show that the proposed method is robust against common signal processing attacks and de-synchronization attacks, such as re-quantization, resampling, MP3 compression, cropping, and so on. Comparisons with the existing methods also show the superiority of our proposed method.},
	journal = {IEEE Access},
	author = {Li, Mianjie and Yuan, Xiaochen and Li, Jianqing},
	year = {2018},
	note = {Conference Name: IEEE Access},
	keywords = {Watermarking, Discrete wavelet transforms, Continuous wavelet transforms, Distortion-compensated dither modulation (DC-DM), Dual-tree complex wavelet transform (DT CWT), Flowcharts, local audio watermarking, minimum distance decoding, Modulation},
	pages = {60834--60842},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/ZL8G3FJ8/8492419.html:text/html;Li et al_2018_Dual-Tree Complex Wavelet Transform Based Audio Watermarking Using.pdf:/Users/maodou/Zotero/storage/BXWRYKSL/Li et al_2018_Dual-Tree Complex Wavelet Transform Based Audio Watermarking Using.pdf:application/pdf},
}

@article{YUAN2018103,
	title = {Local multi-watermarking method based on robust and adaptive feature extraction},
	volume = {149},
	issn = {0165-1684},
	url = {https://www.sciencedirect.com/science/article/pii/S0165168418301051},
	doi = {https://doi.org/10.1016/j.sigpro.2018.03.007},
	abstract = {This paper proposes a local multi-watermarking method based on robust and adaptive feature extraction. The Robust and Adaptive Feature Detector based on DAISY Descriptor (RAF3D) is proposed to extract the feature regions of high robustness and stability. The multi-watermarking method is proposed to embed the multiple watermarks simultaneously into the same extracted feature region. In this way, the capacity will be flexible with either the number of feature regions or the number of watermarks. In the proposed method, the Gram–Schmidt process is applied to embed the watermarks in orthogonal spaces, which guarantees the multiple watermarks can be extracted independently. By repeatedly embedding the watermarks into the numerous feature regions, the success rate of watermark detection can be greatly strengthened. In addition, the local embedding strategy improves the imperceptibility of the watermarked image. Extensive experiments are conducted to evaluate the performance of the proposed scheme and the comparison with several existing methods demonstrate that the proposed scheme outperforms the existing methods in terms of the robustness against various attacks.},
	journal = {Signal Processing},
	author = {Yuan, Xiao-Chen and Li, Mianjie},
	year = {2018},
	keywords = {Gram–Schmidt process, Local multi-watermarking, Robust and adaptive feature detector},
	pages = {103--117},
}

@article{chen_triple-classification_2019,
	title = {Triple-{Classification} of {Respiratory} {Sounds} {Using} {Optimized} {S}-{Transform} and {Deep} {Residual} {Networks}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2903859},
	abstract = {Digital respiratory sounds provide valuable information for telemedicine and smart diagnosis in an non-invasive way of pathological detection. As the typical continuous abnormal respiratory sound, wheeze is clinically correlated with asthma or chronic obstructive lung diseases. Meanwhile, the discontinuous adventitious crackle is clinically correlated with pneumonia, bronchitis, and so on. The detection and classification of both attract many studies for decades. However, due to the contained artifacts and constrained feature extraction methods, the reliability and accuracy of the classification of wheeze, crackle, and normal sounds need significant improvement. In this paper, we propose a novel method for the identification of wheeze, crackle, and normal sounds using the optimized S-transform (OST) and deep residual networks (ResNets). First, the raw respiratory sound is processed by the proposed OST. Then, the spectrogram of OST is rescaled for the Resnet. After the feature learning and classification are fulfilled by the ResNet, the classes of respiratory sounds are recognized. Because the proposed OST highlights the features of wheeze, crackle, and respiratory sounds, and the deep residual learning generates discriminative features for better recognition, this proposed method provides reliable access for respiratory disease-related telemedicine and E-health diagnosis. The experimental results show that the proposed OST and ResNet is excellent for the multi-classification of respiratory sounds with the accuracy, sensitivity, and specificity up to 98.79\%, 96.27\% and 100\%, respectively. The comparison results of the triple-classification of respiratory sounds indicate that the proposed method outperforms the deep-learning-based ensembling convolutional neural network (CNN) by 3.23\% and the empirical mode decomposition-based artificial neural network (ANN) by 4.63\%, respectively.},
	journal = {IEEE Access},
	author = {Chen, Hai and Yuan, Xiaochen and Pei, Zhiyuan and Li, Mianjie and Li, Jianqing},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {Feature extraction, Training, Transforms, crackle and wheeze detection, Deep residual networks (ResNet), Diseases, Lung, optimized S-transform (OST), respiratory sounds classification, Spectrogram, Time-frequency analysis},
	pages = {32845--32852},
	file = {Chen et al_2019_Triple-Classification of Respiratory Sounds Using Optimized S-Transform and.pdf:/Users/maodou/Zotero/storage/NL3GFR8H/Chen et al_2019_Triple-Classification of Respiratory Sounds Using Optimized S-Transform and.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/RHXL2GPA/8663379.html:text/html},
}

@article{CHEN2019163,
	title = {Automatic multi-level in-exhale segmentation and enhanced generalized {S}-transform for wheezing detection},
	volume = {178},
	issn = {0169-2607},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260719305048},
	doi = {https://doi.org/10.1016/j.cmpb.2019.06.024},
	abstract = {Background and objective Wheezing is a common symptom of patients caused by asthma and chronic obstructive pulmonary diseases. Wheezing detection identifies wheezing lung sounds and helps physicians in diagnosis, monitoring, and treatment of pulmonary diseases. Different from the traditional way to detect wheezing sounds using digital image process methods, automatic wheezing detection uses computerized tools or algorithms to objectively and accurately assess and evaluate lung sounds. We propose an innovative machine learning-based approach for wheezing detection. The phases of the respiratory sounds are separated automatically and the wheezing features are extracted accordingly to improve the classification accuracy. Methods To enhance the features of wheezing for classification, the Adaptive Multi-Level In-Exhale Segmentation (AMIE$_{\textrm{S}}$EG) is proposed to automatically and precisely segment the respiratory sounds into inspiratory and expiratory phases. Furthermore, the Enhanced Generalized S-Transform (EGST) is proposed to extract the wheezing features. The highlighted features of wheezing improve the accuracy of wheezing detection with machine learning-based classifiers. Results To evaluate the novelty and superiority of the proposed AMIE$_{\textrm{S}}$EG and EGST for wheezing detection, we employ three machine learning-based classifiers, Support Vector Machine (SVM), Extreme Learning Machine (ELM) and K-Nearest Neighbor (KNN), with public datasets at segment level and record level respectively. According to the experimental results, the proposed method performs the best using the KNN classifier at segment level, with the measured accuracy, sensitivity, specificity as 98.62\%, 95.9\% and 99.3\% in average respectively. On the other aspect, at record level, the three classifiers perform excellent, with the accuracy, sensitivity, specificity up to 99.52\%, 100\% and 99.27\% respectively. We validate the method with public respiratory sounds dataset. Conclusion The comparison results indicate the very good performance of the proposed methods for long-term wheezing monitoring and telemedicine.},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Chen, Hai and Yuan, Xiaochen and Li, Jianqing and Pei, Zhiyuan and Zheng, Xiaobin},
	year = {2019},
	keywords = {Adaptive Multi-Level In-Exhale Segmentation (AMIE$_{\textrm{S}}$EG), Enhanced Generalized S Transform, Feature enhancement, Wheezing detection},
	pages = {163--173},
}

@article{yuan_gramschmidt_2020,
	title = {Gram–{Schmidt} {Orthogonalization}-{Based} {Audio} {Multiple} {Watermarking} {Scheme}},
	volume = {39},
	number = {8},
	journal = {Circuits, Systems, and Signal Processing},
	author = {Yuan, Xiaochen and Li, Mianjie},
	year = {2020},
	note = {ISBN: 1531-5878
Publisher: Springer},
	pages = {3958--3977},
}

@article{li_quaternion_2020,
	title = {Quaternion {Discrete} {Fourier} {Transform}-{Based} {Color} {Image} {Watermarking} {Method} {Using} {Quaternion} {QR} {Decomposition}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.2987914},
	abstract = {In this paper, a new Quaternion Discrete Fourier Transform (QDFT)-based digital color image watermarking method is presented. In addition, the Quaternion QR (QQR) decomposition is applied in digital watermarking technology for the first time. First of all, the QDFT and QQR decomposition are performed on the host image, respectively, to acquire the scalar part of the quaternion matrix for watermark information embedding. After that, we divide the scalar part of the quaternion matrix generated by the QQR decomposition into blocks and calculate the entropy. The block with high entropy is selected to embed the watermark information. Then the watermark information is embedded into the extracted block using the quantization index modulation method. We conducted a large number of tests and experimental results indicate that the presented approach obtains excellent robustness against Scaling, Rotation, Median filtering, `Salt \& Pepper' noise, and JPEG Compression. Compared with the existing methods, the presented method achieves better performance.},
	journal = {IEEE Access},
	author = {Li, Mianjie and Yuan, Xiaochen and Chen, Hai and Li, Jianqing},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Watermarking, Transforms, Color, Data mining, Entropy, Matrix decomposition, quantization index modulation, quaternion discrete Fourier transform (QDFT), quaternion QR (QQR) decomposition, Quaternions, scalar part, Watermarking technology},
	pages = {72308--72315},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/NWIMC37Y/9066976.html:text/html;Li et al_2020_Quaternion Discrete Fourier Transform-Based Color Image Watermarking Method.pdf:/Users/maodou/Zotero/storage/Z2XZX5EW/Li et al_2020_Quaternion Discrete Fourier Transform-Based Color Image Watermarking Method.pdf:application/pdf},
}

@article{li_adaptive_2020,
	title = {Adaptive segmentation-based feature extraction and {S}-{STDM} watermarking method for color image},
	volume = {32},
	number = {13},
	journal = {Neural Computing and Applications},
	author = {Li, Mianjie and Yuan, Xiaochen},
	year = {2020},
	note = {ISBN: 1433-3058
Publisher: Springer},
	pages = {9181--9200},
}

@article{yuan_spatial_2020,
	title = {Spatial {Domain}-{Based} {Nonlinear} {Residual} {Feature} {Extraction} for {Identification} of {Image} {Operations}},
	volume = {10},
	number = {16},
	journal = {Applied Sciences},
	author = {Yuan, Xiaochen and Huang, Tian},
	year = {2020},
	note = {ISBN: 2076-3417
Publisher: MDPI},
	pages = {5582},
}

@article{YUAN2021116038,
	title = {Gauss–{Jordan} elimination-based image tampering detection and self-recovery},
	volume = {90},
	issn = {0923-5965},
	url = {https://www.sciencedirect.com/science/article/pii/S0923596520301855},
	doi = {https://doi.org/10.1016/j.image.2020.116038},
	abstract = {This paper proposes a novel Gauss–Jordan elimination-based image tampering detection and self-recovery scheme, aiming at dealing with the problem of malicious tampering on digital images. To deal with the copy–move tampering which is challenging because the tampered region may contain the watermark information, we propose the Improved Check Bits Generation algorithm during watermark generation, to generate the check bits for tampering detection. Meanwhile, the recovery bits are reconstructed according to the fundamental of Gauss–Jordan Elimination, for purpose of image contents self-recovery. To improve the accuracy of detection and the quality of recovered images, we propose the Morphological Processing-Based Enhancement method and the Edge Extension preprocessing respectively during and after the tampering detection Finally, the Gauss–JordanElimination-Based Self-Recovery method is proposed to recover the damaged content mathematically on basis of the detected results. By employing the unchanged recovery bits which are embedded in the non-tampered region, the failure in recovery caused by the damaged recovery bits can be completely avoided. A large number of experiments have been conducted to show the very good performance of the proposed scheme. The precision, recall, and F1 score are calculated for evaluation of tampering detection, while the PSNR values are calculated for evaluation of image recovery. The comparisons with the state-of-the-art methods show that the proposed scheme shows the superiorities in terms of imperceptibility, security and recovery capability. The experimental result indicates the average PSNR of recovered image is 44.415dB.},
	journal = {Signal Processing: Image Communication},
	author = {Yuan, Xiaochen and Li, Xinhang and Liu, Tong},
	year = {2021},
	keywords = {Gauss–Jordan Elimination-Based Self-Recovery, Image tampering detection, Improved check bits generation, Morphological processing-based enhancement},
	pages = {116038},
}

@article{liu_adaptive_2021,
	title = {Adaptive {Feature} {Calculation} and {Diagonal} {Mapping} for {Successive} {Recovery} of {Tampered} {Regions}},
	volume = {31},
	issn = {1558-2205},
	doi = {10.1109/TCSVT.2020.3032455},
	abstract = {This article proposes an adaptive scheme for image tampered region localization and content recovery. To generate the watermark information comprised of the authentication data and recovery data, we firstly propose the Adaptive Authentication Feature Calculation algorithm to obtain the authentication data, which includes the information of block location and block feature. The DWT-based Block Feature Calculation method is then proposed to calculate the block feature, and the quantization method is employed to calculate the block location. The recovery data is composed of self-recovery bits and mapped-recovery bits. The self-recovery bits are obtained by the Set Partitioning in Hierarchical Trees encoding algorithm. For retrieving the damaged codes caused by tampering, we propose the Diagonal Mapping algorithm and apply it to the self-recovery bits, thus generating the mapped-recovery bits, to provide a guarantee of recovery data. Experimental results show the superior performance of the proposed scheme in terms of tamper detection and image recovery, by comparing with the state-of-the-art works. The results demonstrate that the proposed method shows efficiency in the adaptiveness, well localization, strong capability for image recovery, and the effectiveness of attack resistance.},
	number = {7},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {Liu, Tong and Yuan, Xiaochen},
	month = jul,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Circuits and Systems for Video Technology},
	keywords = {Image coding, Watermarking, Authentication, Partitioning algorithms, Adaptive authentication feature calculation, diagonal mapping, Discrete wavelet transforms, DWT-based block feature calculation, Media, successive content self-recovery, tamper detection},
	pages = {2617--2630},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/B6G3PZ4X/9233407.html:text/html;Liu_Yuan_2021_Adaptive Feature Calculation and Diagonal Mapping for Successive Recovery of.pdf:/Users/maodou/Zotero/storage/8K3335T4/Liu_Yuan_2021_Adaptive Feature Calculation and Diagonal Mapping for Successive Recovery of.pdf:application/pdf},
}

@article{liu_dual-tamper-detection_2021,
	title = {A dual-tamper-detection method for digital image authentication and content self-recovery},
	volume = {80},
	number = {19},
	journal = {Multimedia Tools and Applications},
	author = {Liu, Tong and Yuan, Xiaochen},
	year = {2021},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {29805--29826},
}

@article{li_fd-tr_2021,
	title = {{FD}-{TR}: feature detector based on scale invariant feature transform and bidirectional feature regionalization for digital image watermarking},
	volume = {80},
	number = {21},
	journal = {Multimedia Tools and Applications},
	author = {Li, Mianjie and Yuan, Xiaochen},
	year = {2021},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {32197--32217},
}

@article{FANG2022295,
	title = {Detection of weak electromagnetic interference attacks based on fingerprint in {IIoT} systems},
	volume = {126},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X21003289},
	doi = {https://doi.org/10.1016/j.future.2021.08.020},
	abstract = {In Industrial Internet of Things (IIoT) systems, the intelligent devices are vulnerable to be attacked by weak Electromagnetic Interference (EMI), thereby threatening the security of the systems. Therefore, it is of great significance to investigate the weak EMI attack of IIoT systems. The different manufacturing processes and deployment environments make the intelligent devices carry different noises, called fingerprints, which are unchanged unless these intelligent devices are attacked. Hence, we can detect weak EMI attacks by judging whether the fingerprint of intelligent device has been changed, which is different from using professional detection equipment as in other methods. Based on the fingerprint of intelligent device, this paper proposes a highly efficient weak EMI attack detection method which is divided into three steps. First, the fingerprint is extracted by Linear Time-Invariant (LTI) model and Kalman algorithm. Second, according to the extracted fingerprint, a fusion model is designed to determine whether the device is attacked by weak EMI. In the fusion model, Feature Extraction Unit (FEU) combines with Long Short-Term Memory (LSTM) to improve the detection accuracy. Finally, an edge computing framework is proposed to enhance the efficiency of the method. The experimental results show that the detection accuracy and the efficiency of the proposed method are 5.2\% and 42.2\% higher than those of the state-of-the-art method, respectively.},
	journal = {Future Generation Computer Systems},
	author = {Fang, Kai and Wang, Tingting and Yuan, Xiaochen and Miao, Chunyu and Pan, Yuanyuan and Li, Jianqing},
	year = {2022},
	keywords = {Edge computing, EMI attack, FEU-LSTM, Fingerprint, IIoT},
	pages = {295--304},
}

@article{wang_reinforcement_2022,
	title = {Reinforcement {Learning}-{Based} {Optimization} for {Mobile} {Edge} {Computing} {Scheduling} {Game}},
	issn = {2471-285X},
	doi = {10.1109/TETCI.2022.3145694},
	abstract = {Task scheduling on edge computing servers is a critical concern affecting user experience. Current scheduling methods attain an overall appealing performance through centralized control. Nevertheless, forcing users to act based on a centralized control is impractical. Hence, this work suggests a game theory-based distributed edge computing server task scheduling model. The proposed method comprehensively considers the mobile device-server link quality and the server’s computing resource allocation and balances link quality and computing resources requirements when selecting edge computing servers. Furthermore, we develop a time series prediction algorithm based on IndRNN and LSTM to accurately predict link quality. Once Nash equilibrium is reached quickly through our proposed acceleration scheme, the proposed model provides various QoS for different priority users. The experimental results highlight that the developed solution provides differentiated services while optimizing computing resource scheduling and ensuring an approximate Nash equilibrium in polynomial time.},
	journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
	author = {Wang, Tingting and Lu, Bingxian and Wang, Wei and Wei, Wei and Yuan, Xiaochen and Li, Jianqing},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Emerging Topics in Computational Intelligence},
	keywords = {Task analysis, Computational modeling, 5G mobile communication, Delays, edge computing, game theory, Games, Mobile Computing, Processor scheduling, scheduling, Servers},
	pages = {1--10},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/C53M3VBM/9704867.html:text/html;Wang et al_2022_Reinforcement Learning-Based Optimization for Mobile Edge Computing Scheduling.pdf:/Users/maodou/Zotero/storage/69UR33GI/Wang et al_2022_Reinforcement Learning-Based Optimization for Mobile Edge Computing Scheduling.pdf:application/pdf},
}

@article{li_alteration_2021,
	title = {Alteration {Detection} of {Multispectral}/{Hyperspectral} {Images} {Using} {Dual}-{Path} {Partial} {Recurrent} {Networks}},
	volume = {13},
	number = {23},
	journal = {Remote Sensing},
	author = {Li, Jinlong and Yuan, Xiaochen and Feng, Li},
	year = {2021},
	note = {ISBN: 2072-4292
Publisher: MDPI},
	pages = {4802},
}

@article{chen_rs-chain_2022,
	title = {{RS}-chain: a decentralized reputation-sharing framework for group-buying industry via hybrid blockchain},
	journal = {Cluster Computing},
	author = {Chen, Yungui and Feng, Li and Liang, Hong and Yao, Shumin and Tian, Liwei and Yuan, Xiaochen},
	year = {2022},
	note = {ISBN: 1573-7543
Publisher: Springer},
	pages = {1--16},
}

@article{zhang_blind_2022,
	title = {Blind {Dual} {Watermarking} {Scheme} {Using} {Stucki} {Kernel} and {SPIHT} for {Image} {Self}-{Recovery}},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3204865},
	abstract = {In this paper we propose a blind dual watermarking scheme using Set Partitioning in Hierarchical Trees (SPIHT) and Stucki Kernel halftone technique for the tamper detection and image self-recovery. The watermark consists of authentication bits for tampering area location and recovery bits for image restoration. We generate two recovery bits to ensure the high-quality recovery of the tampered image. The primary recovery bit is generated by the SPIHT encoding, and the secondary recovery bit is generated by the Stucki Kernel halftone technique. Then the authentication bit is generated based on the recovery bits. Before embedding the watermark, we shuffle the watermark bits through Arnold cat mapping and diagonal mapping to improve the security and quality of the restored image. LSB-based watermarking technique is used to embed the watermark into the original image to ensure the invisibility of the watermarked image. Experiments have been conducted on two datasets, BOW2 and USC-SIPI, and results show that the proposed scheme can achieve high restoration quality. Comparison with the existing works demonstrate the good performance and superiority of the proposed scheme.},
	journal = {IEEE Access},
	author = {Zhang, Qiyuan and Yuan, Xiaochen and Liu, Tong},
	year = {2022},
	note = {Conference Name: IEEE Access},
	keywords = {Kernel, Image coding, Watermarking, Authentication, Discrete wavelet transforms, Arnold cat map, authentication bit, Discrete cosine transforms, Image restoration, image self-recovery, Set partitioning in hierarchical trees (SPIHT), Stucki Kernel halftone technique},
	pages = {96100--96111},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/3TZK5Z3V/9878311.html:text/html;Zhang et al_2022_Blind Dual Watermarking Scheme Using Stucki Kernel and SPIHT for Image.pdf:/Users/maodou/Zotero/storage/76I36GZK/Zhang et al_2022_Blind Dual Watermarking Scheme Using Stucki Kernel and SPIHT for Image.pdf:application/pdf},
}

@article{li_cd-sdn_2022,
	title = {{CD}-{SDN}: {Unsupervised} {Sensitivity} {Disparity} {Networks} for {Hyper}-{Spectral} {Image} {Change} {Detection}},
	volume = {14},
	number = {19},
	journal = {Remote Sensing},
	author = {Li, Jinlong and Yuan, Xiaochen and Li, Jinfeng and Huang, Guoheng and Li, Ping and Feng, Li},
	year = {2022},
	note = {ISBN: 2072-4292
Publisher: MDPI},
	pages = {4806},
}

@article{LI2022,
	title = {Power normalized cepstral robust features of deep neural networks in a cloud computing data privacy protection scheme},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231222013741},
	doi = {https://doi.org/10.1016/j.neucom.2022.11.001},
	abstract = {Deep Neural Networks (DNNs) have developed rapidly in data privacy protection applications such as medical treatment and finance. However, DNNs require high-speed and high-memory computers in terms of computation, otherwise training can be very lengthy. Furthermore, DNNs are often not available in resource-constrained mobile devices. Therefore, training and executing DNNs are increasingly using cloud computing. In the paper, the Power Normalized Cepstrum-based Robust Feature Detector (PNC-RFD), with deep learning in the cloud computing, is proposed for data privacy protection. The proposed PNC-RFD extracts a specified number of signal segments of high robustness used to embed and extract various data. For the sake of embedding and extracting the data, a method of information hiding employing Dual-Tree Complex Wavelet Packet Transform (DT CWPT) is therefore presented. The presented scheme simultaneously embeds multiple data into coefficients of the DT CWPT of signal segments. By embedding the data into the orthogonal spaces, the proposed method ensures the independent extraction of the multiple data. In line with the performance analysis, the superiority of the presented scheme is elaborated through making the comparison with the current state-of-the-art methods.},
	journal = {Neurocomputing},
	author = {Li, Mianjie and Tian, Zhihong and Du, Xiaojiang and Yuan, Xiaochen and Shan, Chun and Guizani, Mohsen},
	year = {2022},
	keywords = {Cloud Computing, Data Privacy Protection, Data Security, Deep Neural Networks (DNNs), Power Normalized Cepstrum-based Robust Feature Detector (PNC-RFD)},
}

@article{sun_reversible_2022,
	title = {Reversible multi-watermarking for color images with grayscale invariance},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-022-14125-y},
	doi = {10.1007/s11042-022-14125-y},
	abstract = {As a special way of hiding information, reversible data hiding is mostly used to embed data into digital multimedia. The original multimedia and embedded data can be restored from the watermarked one without any loss. Being different from the traditional reversible data hiding methods, the gray scale-invariant reversible watermarking method, which keeps the grayscale of image unchanged as the information is embedded, is proposed for color images recently. Although color images are widely used in practice, there are more reversible data hiding algorithms and feature points extraction algorithms for gray images rather than color images. In this paper, two multiple watermarking mechanisms have been proposed for color images with grayscale invariance, the multi-level watermarking mechanism, where one feature region is selected and the watermarks are embedded for multiple times, and the multi-region watermarking mechanism, where the multiple non-overlapping feature regions are selected to embed watermarks. Different from others, the former mechanism uses multiple embeddings based on the feature regions to increase the embedding capacity and the latter one uses local embedding instead of global embedding to reduce the impact on the whole image. At the same time, the selection of feature points can meet certain conditions and get more suitable regions for information embedding. Experimental results show that the proposed scheme can extend the capacity efficiently while keep the characteristic of grayscale invariance.},
	journal = {Multimedia Tools and Applications},
	author = {Sun, Ying and Yuan, Xiaochen and Wang, Xingrun and Li, Jianqing},
	month = nov,
	year = {2022},
}

@article{wang_parallel_2022,
	title = {Parallel {Multiple} {Watermarking} {Using} {Adaptive} {Inter}-{Block} {Correlation}},
	journal = {Expert Systems with Applications},
	author = {Wang, Xingrun and Yuan, Xiaochen and Li, Mianjie and Sun, Ying and Tian, Jinyu and Guo, Hongfei and Li, Jianqing},
	year = {2022},
	note = {ISBN: 0957-4174
Publisher: Elsevier},
	pages = {119011},
}

@article{zhang_collaborative_2022,
	title = {Collaborative multi-feature extraction and scale-aware semantic information mining for medical image segmentation},
	volume = {67},
	issn = {0031-9155, 1361-6560},
	url = {https://iopscience.iop.org/article/10.1088/1361-6560/ac95f5},
	doi = {10.1088/1361-6560/ac95f5},
	abstract = {Objective. In recent years, methods based on U-shaped structure and skip connection have achieved remarkable results in many medical semantic segmentation tasks. However, the information integration capability of this structure is still limited due to the incompatibility of feature maps of encoding and decoding stages at corresponding levels and lack of extraction of valid information in the ﬁnal stage of encoding. This structural defect is particularly obvious in segmentation tasks with non-obvious, small and blurred-edge targets. Our objective is to design a novel segmentation network to solve the above problems. Approach. The segmentation network named Global Context-Aware Network is mainly designed by inserting a Multi-feature Collaboration Adaptation (MCA) module, a Scale-Aware Mining (SAM) module and an Edge-enhanced Pixel Intensity Mapping (Edge-PIM) into the U-shaped structure. Firstly, the MCA module can integrate information from all encoding stages and then effectively acts on the decoding stages, solving the problem of information loss during downsampling and pooling. Secondly, the SAM module can further mine information from the encoded high-level features to enrich the information passed to the decoding stage. Thirdly, EdgePIM can further reﬁne the segmentation results by edge enhancement. Main results. We newly collect Magnetic Resonance Imaging of Colorectal Cancer Liver Metastases (MRI-CRLM) dataset in different imaging sequences with non-obvious, small and blurred-edge liver metastases. Our method performs well on the MRI-CRLM dataset and the publicly available ISIC-2018 dataset, outperforming state-ofthe-art methods such as CPFNet on multiple metrics after boxplot analysis, indicating that it can perform well on a wide range of medical image segmentation tasks. Signiﬁcance. The proposed method solves the problem mentioned above and improved segmentation accuracy for non-obvious, small and blurred-edge targets. Meanwhile, the proposed visualization method Edge-PIM can make the edge more prominent, which can assist medical radiologists in their research work well.},
	language = {en},
	number = {20},
	urldate = {2022-11-02},
	journal = {Physics in Medicine \& Biology},
	author = {Zhang, Ruijun and He, Zixuan and Zhu, Jian and Yuan, Xiaochen and Huang, Guoheng and Pun, Chi-Man and Peng, Jianhong and Lin, Junzhong and Zhou, Jian},
	month = oct,
	year = {2022},
	pages = {205008},
	file = {Zhang 等 - 2022 - Collaborative multi-feature extraction and scale-a.pdf:/Users/maodou/Zotero/storage/WWKZTYZI/Zhang 等 - 2022 - Collaborative multi-feature extraction and scale-a.pdf:application/pdf},
}

@inproceedings{yuan_invariant_2012,
	title = {Invariant {Image} {Watermarking} {Using} {Harris} {Feature} {Extraction} and {Zernike} {Moments}},
	booktitle = {{ISA} 2012},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	year = {2012},
}

@inproceedings{pun_robust_2009,
	title = {Robust {Block} and {Gray}-{Level} {Histogram} {Based} {Watermarking} {Scheme}},
	booktitle = {Pacific-{Rim} {Conference} on {Multimedia}},
	publisher = {Springer},
	author = {Pun, Chi-Man and Yuan, Xiaochen},
	year = {2009},
	pages = {590--601},
}

@inproceedings{li_robust_2018,
	title = {Robust digital image watermarking using distortion-compensated dither modulation},
	volume = {10615},
	booktitle = {Ninth {International} {Conference} on {Graphic} and {Image} {Processing} ({ICGIP} 2017)},
	publisher = {SPIE},
	author = {Li, Mianjie and Yuan, Xiaochen},
	year = {2018},
	pages = {1368--1375},
}

@inproceedings{li_image_2018,
	title = {Image segmentation-based robust feature extraction for color image watermarking},
	volume = {10615},
	booktitle = {Ninth {International} {Conference} on {Graphic} and {Image} {Processing} ({ICGIP} 2017)},
	publisher = {SPIE},
	author = {Li, Mianjie and Deng, Zeyu and Yuan, Xiaochen},
	year = {2018},
	pages = {358--364},
}

@inproceedings{bi_over-segmentation_2015,
	title = {Over-{Segmentation} {Based} {Image} {Forgery} {Detection}},
	isbn = {94-6252-095-X},
	booktitle = {2015 {International} {Conference} on {Electronic} {Science} and {Automation} {Control}},
	publisher = {Atlantis Press},
	author = {Bi, Xiu-Li and Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2015},
	pages = {23--26},
}

@inproceedings{pun_reversible_2010,
	title = {Reversible image watermarking using integer transform on {Lifting} wavelet coefficients},
	abstract = {A novel reversible watermarking scheme based on 2-D Lifting wavelet transform, LWT2, integer transform and block linking method is presented in the paper. LWT2 produces coefficient subbands whose values are in integer form. The integer transform is then applied for embedding watermark bits. In addition, the simple and fast block linking method is used for indicating the embedding location. Experimental results show that our proposed method can achieve high capacity for image watermarking while preserve good image quality.},
	booktitle = {6th {International} {Conference} on {Digital} {Content}, {Multimedia} {Technology} and its {Applications}},
	author = {Pun, Chi-Man and Hemman, Nopporn and Yuan, Xiao-Chen},
	month = aug,
	year = {2010},
	keywords = {Watermarking, Bit rate, PSNR},
	pages = {390--394},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/FJR8X6RA/5568615.html:text/html;Pun et al_2010_Reversible image watermarking using integer transform on Lifting wavelet.pdf:/Users/maodou/Zotero/storage/CE7RK9P9/Pun et al_2010_Reversible image watermarking using integer transform on Lifting wavelet.pdf:application/pdf},
}

@inproceedings{yuan_digital_2010,
	title = {Digital image watermarking scheme based on histogram in {DWT} domain},
	abstract = {A robust and geometric invariant digital watermarking scheme for gray-level images is proposed in this paper. The scheme carries out watermark embedding and extraction based on histogram in DWT domain. For watermark embedding, the original image is decomposed into the approximation and details sub-bands. Pixels of the approximation sub-band are grouped into m blocks, each of which has the same number of intensity-levels, thus the block histogram is generated; with the block histogram, pixels are moved to form a specific pattern in the intensity-level histogram distribution, indicating the watermark. For watermark extraction, the watermarked image is decomposed into the approximation and details sub-bands; then the pixels in the approximation sub-band are grouped into blocks in the similar manner. According to the histogram distribution in each block, the watermark is extracted. Experimental results show that the proposed scheme is highly robust against JPEG compression, geometric attacks and some common signal processing.},
	booktitle = {6th {International} {Conference} on {Digital} {Content}, {Multimedia} {Technology} and its {Applications}},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	month = aug,
	year = {2010},
	keywords = {Robustness, Image coding, Transform coding, Discrete wavelet transforms, Cryptography, Discrete Wavelet Transform, Fractals, Geometric Invariant, Histogram, Pixel, Robust Watermarking},
	pages = {395--399},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/R4MGNA42/5568608.html:text/html;Yuan_Pun_2010_Digital image watermarking scheme based on histogram in DWT domain.pdf:/Users/maodou/Zotero/storage/LSXEF2ET/Yuan_Pun_2010_Digital image watermarking scheme based on histogram in DWT domain.pdf:application/pdf},
}

@inproceedings{yuan_invariant_2011,
	title = {Invariant {Digital} {Image} {Watermarking} {Using} {Adaptive} {Harris} {Corner} {Detector}},
	doi = {10.1109/CGIV.2011.22},
	abstract = {A robust and geometric invariant digital image watermarking scheme based on feature extraction and histogram distribution is proposed in this paper. The feature extraction method called Harris Corner Detector is adopted and revised by adjusting the response threshold value and ranking the response R value to extract feature points and thus define the regions for watermark data bits embedding and extraction. Each embedding region is a square matrix centering at the selected feature points. For watermark embedding, some pixels are moved to form a specific pattern in the intensity-level histogram distribution in each embedding region, indicating the watermark. For watermark extraction, the Adaptive Harris Corner Detector is adopted to restore the image to its original un-rotated position. According to the intensity-level histogram distribution in each embedded region, the watermark is extracted. Experimental results show that the proposed scheme is very robust against rotation, scaling, JPEG compression, median filtering, low-pass Gaussian filtering and also noise pollution.},
	booktitle = {Imaging and {Visualization} 2011 {Eighth} {International} {Conference} {Computer} {Graphics}},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	month = aug,
	year = {2011},
	keywords = {Feature extraction, Robustness, Detectors, Watermarking, Filtering, Geometric Invariant, Feature Extraction, Harris Corner Detector, Histogram Distribution, Histograms, Signal processing},
	pages = {109--113},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/7PNFJGRZ/6054097.html:text/html;Yuan_Pun_2011_Invariant Digital Image Watermarking Using Adaptive Harris Corner Detector.pdf:/Users/maodou/Zotero/storage/SM8FS7UA/Yuan_Pun_2011_Invariant Digital Image Watermarking Using Adaptive Harris Corner Detector.pdf:application/pdf},
}

@inproceedings{pun_geometric_2011,
	title = {Geometric {Invariant} {Digital} {Image} {Watermarking} {Scheme} {Based} on {Feature} {Points} {Detector} and {Histogram} {Distribution}},
	doi = {10.1109/TrustCom.2011.24},
	abstract = {A robust and geometric invariant digital image watermarking scheme based on SIFT Based Feature Points Detector (SIFTFPD) and histogram distribution is proposed in this paper. The SIFTFPD is proposed to extract geometric invariant feature points from the host image for watermark embedding; and the descriptor is generated subsequently. With the feature extraction procedure, the circular regions centered at the extracted feature points and with the given radius are defined as embedding regions. For watermark embedding, some pixels are moved to form a specific pattern in the intensity-level histogram distribution in each embedding region, to indicate the watermark. For watermark extraction, the embedded regions are generated with the descriptor and according to the intensity-level histogram distribution in each region, the watermark can be extracted. Experimental results show that the proposed scheme is very robust against geometric distortion such as rotation, scaling, cropping, and affine transformation; and common signal processing, such as JPEG compression, median filtering, and Gaussian low-pass filtering.},
	booktitle = {{2011IEEE} 10th {International} {Conference} on {Trust}, {Security} and {Privacy} in {Computing} and {Communications}},
	author = {Pun, Chi-Man and Yuan, Xiao-Chen and Chen, C. L. Philip},
	month = nov,
	year = {2011},
	note = {ISSN: 2324-9013},
	keywords = {Feature extraction, Robustness, Detectors, Watermarking, Geometric Invariant, Feature Extraction, Histogram Distribution, Histograms, Databases, Distortion, SIFT},
	pages = {166--172},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/UZFPSMBG/6120816.html:text/html;Pun et al_2011_Geometric Invariant Digital Image Watermarking Scheme Based on Feature Points.pdf:/Users/maodou/Zotero/storage/C2CVPW89/Pun et al_2011_Geometric Invariant Digital Image Watermarking Scheme Based on Feature Points.pdf:application/pdf},
}

@inproceedings{yuan_geometric_2012,
	title = {A {Geometric} {Invariant} {Digital} {Image} {Watermarking} {Scheme} {Based} on {Robust} {Feature} {Detector} and {Local} {Zernike} {Moments}},
	doi = {10.1109/CGIV.2012.17},
	abstract = {A robust and geometric invariant digital image watermarking scheme based on robust feature points detector and local Zernike transform is proposed in this paper. The robust feature points detector is proposed based on SIFT algorithm to extract circular patches. A local Zernike moments-based watermarking scheme is raised. Each extracted circular patch is decomposed into a collection of binary patches and Zernike transform is applied to the appointed binary patches. Experimental results show that the proposed scheme is very robust against geometric distortions and common signal processing.},
	booktitle = {Imaging and {Visualization} 2012 {Ninth} {International} {Conference} on {Computer} {Graphics}},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	month = jul,
	year = {2012},
	keywords = {Digital images, Feature extraction, Robustness, Watermarking, Transforms, Geometric Invariant, Signal processing, SIFT, Local Zernike Transform, Robust Feature Points Detector, Signal processing algorithms},
	pages = {53--56},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/QG5SX9HD/6298348.html:text/html;Yuan_Pun_2012_A Geometric Invariant Digital Image Watermarking Scheme Based on Robust Feature.pdf:/Users/maodou/Zotero/storage/9TGAX9YG/Yuan_Pun_2012_A Geometric Invariant Digital Image Watermarking Scheme Based on Robust Feature.pdf:application/pdf},
}

@inproceedings{yuan_feature_2013,
	title = {Feature {Based} {Video} {Watermarking} {Resistant} to {Geometric} {Distortions}},
	doi = {10.1109/TrustCom.2013.92},
	abstract = {This paper proposes a digital video watermarking scheme which is robust to geometric distortions, such as rotation, scaling, and cropping. The watermark is embedded / extracted based on feature extraction and local Zernike transform in / from each selected frame. The feature extraction method called Adaptive Harris Detector is proposed by adopting and revising the traditional Harris Corner Detector, and the local Zernike moments-based method is raised for watermarking use. In each selected frame, the extracted circular patches are decomposed into a collection of binary patches with Bit-Plane Decomposition method. Magnitudes of the local Zernike moments are calculated by Zernike transform and modified to embed the watermarks. Experimental results show that the proposed watermarking scheme is robust against geometric distortions and meanwhile preserves the imperceptibility of the video. Furthermore, it outperforms comparable methods when tested under common signal processing attacks.},
	booktitle = {2013 12th {IEEE} {International} {Conference} on {Trust}, {Security} and {Privacy} in {Computing} and {Communications}},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	month = jul,
	year = {2013},
	note = {ISSN: 2324-9013},
	keywords = {Feature extraction, Robustness, Detectors, Watermarking, Transforms, Feature Extraction, Signal processing, Local Zernike Transform, Adaptive Harris Detector, Bit-Plane Decomposition, Mobile communication, Video Watermarking},
	pages = {763--767},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/XPMKILSA/6680912.html:text/html;Yuan_Pun_2013_Feature Based Video Watermarking Resistant to Geometric Distortions.pdf:/Users/maodou/Zotero/storage/TMRRG5J4/Yuan_Pun_2013_Feature Based Video Watermarking Resistant to Geometric Distortions.pdf:application/pdf},
}

@inproceedings{yan_adaptive_2015,
	title = {Adaptive local feature based multi-scale image hashing for robust tampering detection},
	doi = {10.1109/TENCON.2015.7373018},
	abstract = {This paper proposes a novel multi-scale image hashing method by using the location-context information of the features generated by adaptive local feature extraction techniques. The adaptive local feature extraction method is proposed for more robust feature descriptors. The global hash is calculated to determine whether the received image has been maliciously tampered. The multi-scale hash is calculated to locate the tampered regions. Experimental results show that the proposed tampering detection scheme is very robust against the content-preserving attacks, including both common signal processing and geometric distortions.},
	booktitle = {{TENCON} 2015 - 2015 {IEEE} {Region} 10 {Conference}},
	author = {Yan, Cai-Ping and Pun, Chi-Man and Yuan, Xiao-Chen},
	month = nov,
	year = {2015},
	note = {ISSN: 2159-3450},
	keywords = {Feature extraction, Robustness, Transform coding, Distortion, Adaptive Local Feature Extraction, Indexes, Location-Context Information, Multi-Scale Image Hashing, Tampering Detection},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/QQF4PWH2/7373018.html:text/html;Yan et al_2015_Adaptive local feature based multi-scale image hashing for robust tampering.pdf:/Users/maodou/Zotero/storage/IHWPQBRM/Yan et al_2015_Adaptive local feature based multi-scale image hashing for robust tampering.pdf:application/pdf},
}

@inproceedings{bi_adaptive_2016,
	title = {Adaptive {Polar} {Based} {Filtering} {Method} for {Image} {Copy}-{Move} {Forgery} {Detection}},
	doi = {10.1109/TrustCom.2016.0161},
	abstract = {In this paper, an Adaptive Polar based Filtering Method is proposed for image copy-move forgery detection. In order to improve the performance of detection method, the post-processing of the matching results is worth being focused on. To filter out the redundant pixels from the initially matched pixels, two pixels sets-Symmetrical Matched Pixels set and Unsymmetrical Matched Pixels set, are extracted from the matched pixel pairs, furthermore, the polar distributions of the two sets are calculated respectively. Then, the filtering thresholds can be adaptively calculated according to the polar distribution, thus the redundant pixels can be filtered out accordingly. Finally, some morphological operations are applied to the remained pixels to generate the detected forged regions. Experimental results show that the proposed scheme can achieve much better detection results compared with the existing state-of-the-art copy-move forgery detection methods.},
	booktitle = {2016 {IEEE} {Trustcom}/{BigDataSE}/{ISPA}},
	author = {Bi, Xiuli and Pun, Chi-Man and Yuan, Xiao-Chen},
	month = aug,
	year = {2016},
	note = {ISSN: 2324-9013},
	keywords = {Adaptive Polar based Filtering Method, Copy-Move Forgery, Polar Distribution},
	pages = {952--956},
	file = {Bi et al_2016_Adaptive Polar Based Filtering Method for Image Copy-Move Forgery Detection.pdf:/Users/maodou/Zotero/storage/E5PIAS8C/Bi et al_2016_Adaptive Polar Based Filtering Method for Image Copy-Move Forgery Detection.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/JBM3DHGW/7847044.html:text/html},
}

@inproceedings{li_robust_2017,
	title = {Robust {Feature} {Extraction} {Based} {Watermarking} {Method} {Using} {Spread} {Transform} {Dither} {Modulation}},
	doi = {10.1109/CMVIT.2017.11},
	abstract = {This paper proposes a local digital image watermarking method based on robust feature extraction. A robust feature extraction method is proposed based on DAISY to extract feature regions. Each feature region is decomposed into approximation and details sub-bands by wavelet transform and the watermark is then embedded into and/or extracted from the approximation coefficients. Spread Transform Dither Modulation is applied to embed and extract the watermark. Multiple copies of watermark images are embedded into the feature regions to increase the success rate of watermark extraction and meanwhile improve the robustness. Experimental results show the very good image quality of the watermarked image and the low Bit Error Rate of watermark extraction. Furthermore, the comparison results indicate the better performance and higher robustness of the proposed scheme when under various attacks comparing with the existing methods.},
	booktitle = {2017 {International} {Conference} on {Machine} {Vision} and {Information} {Technology} ({CMVIT})},
	author = {Li, Mianjie and Yuan, Xiaochen},
	month = feb,
	year = {2017},
	keywords = {Feature extraction, Robustness, Watermarking, Discrete wavelet transforms, Modulation, Information technology, Local Digital Image Watermarking, Robust Feature Extraction, Spread Transform Dither Modulation},
	pages = {18--22},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/3BKB3Z4G/7878648.html:text/html;Li_Yuan_2017_Robust Feature Extraction Based Watermarking Method Using Spread Transform.pdf:/Users/maodou/Zotero/storage/6AT26B63/Li_Yuan_2017_Robust Feature Extraction Based Watermarking Method Using Spread Transform.pdf:application/pdf},
}

@inproceedings{zhan_audio_2017,
	title = {Audio post-processing detection and identification based on audio features},
	doi = {10.1109/ICWAPR.2017.8076681},
	abstract = {As an important communication medium, audios are easily modified or tampered during transmission; thus the authenticity of audios is of high importance. This paper mainly introduces a method to detect audio post-processing based on audio features; the Support Vector Machine (SVM) is applied for classification during the detection. In the proposed method, the Mel Frequency Cepstral Coefficient (MFCC) and the Linear Prediction Coding (LPC) of host audios are calculated as audio features, to which SVM is applied to judge the authenticity of the audios. Experimental results show that the proposed audio feature based method can not only verify the authenticity of speech audio, but also have a significant effect on detecting different types of post-processing operations.},
	booktitle = {2017 {International} {Conference} on {Wavelet} {Analysis} and {Pattern} {Recognition} ({ICWAPR})},
	author = {Zhan, Yunzhen and Yuan, Xiaochen},
	month = jul,
	year = {2017},
	note = {ISSN: 2158-5709},
	keywords = {Multimedia communication, Signal processing, Audio Feature, Audio Post-processing Detection, Cepstrum, Conferences, Linear Prediction Coding (LPC), Linear predictive coding, Mel frequency cepstral coefficient, Mel Frequency Cepstral Coefficient (MFCC), Support Vector Machine (SVM)},
	pages = {154--158},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/QD2PMAQQ/8076681.html:text/html;Zhan_Yuan_2017_Audio post-processing detection and identification based on audio features.pdf:/Users/maodou/Zotero/storage/UML5XPDY/Zhan_Yuan_2017_Audio post-processing detection and identification based on audio features.pdf:application/pdf},
}

@inproceedings{li_image_2018-1,
	title = {Image {Quality} {Estimation} {Using} {Logarithmic} {Spread} {Transform} {Dither} {Modulation}},
	volume = {1},
	doi = {10.1109/ICMLC.2018.8526945},
	abstract = {As a pragmatic and novel application of digital watermarking, image quality estimation has been studied in recent years. In this paper, we propose a watermarking-based image quality evaluation scheme. The Logarithmic Spread Transform Dither Modulation is proposed based on the quantization index modulation and then applied to embed and extract the watermarks. The traditional objective metrics are employed to measure quality of images. We calculate the True Detection Rates (TDR) value to represent degradation of watermark. Considering that the embedded watermark and the watermarked image are distorted simultaneously, the image quality can be evaluated by matching the TDR value with a quality value on a pre-generated curve. Experimental results indicate that the proposed scheme provides a good image quality estimation result. The accuracy of the estimation keeps stabilization under different tested attacks, including JPEG compression, Gaussian noise addition and low-pass filtering.},
	booktitle = {2018 {International} {Conference} on {Machine} {Learning} and {Cybernetics} ({ICMLC})},
	author = {Li, Na and Yuan, Xiaochen},
	month = jul,
	year = {2018},
	note = {ISSN: 2160-1348},
	keywords = {Estimation, Transform coding, Watermarking, Modulation, Image quality, Image quality estimation, Logarithmic spread transform dither modulation, Measurement, Quantization (signal), Quantization index modulation, True detection rates},
	pages = {282--287},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/82NWGCV4/8526945.html:text/html;Li_Yuan_2018_Image Quality Estimation Using Logarithmic Spread Transform Dither Modulation.pdf:/Users/maodou/Zotero/storage/5DYE6MDG/Li_Yuan_2018_Image Quality Estimation Using Logarithmic Spread Transform Dither Modulation.pdf:application/pdf},
}

@inproceedings{huang_detection_2018,
	title = {Detection {And} {Classification} {Of} {Various} {Image} {Operations} {Using} {Deep} {Learning} {Technology}},
	volume = {1},
	doi = {10.1109/ICMLC.2018.8526999},
	abstract = {As one of the main medium for information transmission, the digital imagecan be easily tampered during transmission. It is becoming more and more important to identifywhether the given image is an original image or a processed image. In this paper, we propose acompact universal feature based on spatial domain in virtue of some latest image forensic methods and design a multi-class classification scheme using the deep learning technique, to identify and furthermore classify the various normal image operations. According to the experimental results, the proposed method can well detect and classify the multiple common image post-processing operations. And the comparison with the existing feature shows the better performance of the proposed method.},
	booktitle = {2018 {International} {Conference} on {Machine} {Learning} and {Cybernetics} ({ICMLC})},
	author = {HUANG, TIAN and YUAN, XIAOCHEN},
	month = jul,
	year = {2018},
	note = {ISSN: 2160-1348},
	keywords = {Digital images, Feature extraction, Convolution, Image coding, Filtering, Quantization (signal), Convolutional neural network (CNN), Deep learning technique, Image post-processing Operations detection, Spatial rich model (SRM)},
	pages = {50--55},
	file = {HUANG_YUAN_2018_Detection And Classification Of Various Image Operations Using Deep Learning.pdf:/Users/maodou/Zotero/storage/FINABRRA/HUANG_YUAN_2018_Detection And Classification Of Various Image Operations Using Deep Learning.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/LY5S67KR/8526999.html:text/html},
}

@inproceedings{chen_audio_2018,
	title = {Audio {Amplitude}-{Level} {Quantification} {Vector} for {Identification} of {Audio} {Post}-{Processing} {Operation}},
	doi = {10.1109/SNSP.2018.00050},
	abstract = {Audio tampering is typically followed by post-processing operations to mask the artifacts potentially perceptible by human ears and blur the traces of tampering. However, research on the issue of audio post-processing identification is still a blanket. This paper mainly introduces a method to identify audio post-processing operations. A new audio feature - Audio Amplitude-Level Quantification Vector (AQV) is proposed, then the probability distributions of AQV of audio are calculated and extracted as audio features which are then used for identification of various audio processing. During the detection, the K-Nearest Neighbors (KNN) classifier is applied for classification. Experimental results show that the proposed AQV method can not only verify the authenticity of the speech audio, but also have a significant effect on identifying different types of post-processing operations.},
	booktitle = {2018 {International} {Conference} on {Sensor} {Networks} and {Signal} {Processing} ({SNSP})},
	author = {Chen, Zekun and Yuan, Xiaochen},
	month = oct,
	year = {2018},
	keywords = {Feature extraction, Support vector machines, Training, Audio Feature, Audio Post-processing Detection, Audio Amplitude-Level Quantification Vector (AQV), Classification algorithms, Digital audio players, Gold, K-Nearest Neighbors (KNN), Testing},
	pages = {226--230},
	file = {Chen_Yuan_2018_Audio Amplitude-Level Quantification Vector for Identification of Audio.pdf:/Users/maodou/Zotero/storage/87ZHP933/Chen_Yuan_2018_Audio Amplitude-Level Quantification Vector for Identification of Audio.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/9NULFB62/8615928.html:text/html},
}

@inproceedings{fu_composite_2020,
	title = {Composite {Feature} {Extraction} for {Speech} {Emotion} {Recognition}},
	doi = {10.1109/CSE50738.2020.00018},
	abstract = {This paper proposes an approach for speech emotion recognition based on the composite feature extraction. The traditional paralinguistic and prosodic features and the neurogram features are extracted and concatenated together to be the composite feature. The neural feature is presented by a computational model which outputs a series of responses of a speech's particular characteristic frequency through auditory nerve fiber. The exported responses signals are visualized as the 2D neurogram and then extracted as neural feature. With the extracted composite feature, support vector machines is used to classify the emotion. The eNTERFACE database is used and the various metrics are calculated to evaluate the performance of the proposed approach. Experimental results show that the proposed approach achieves good performances under different conditions and performs better than the related work in terms of the various evaluation metrics.},
	booktitle = {2020 {IEEE} 23rd {International} {Conference} on {Computational} {Science} and {Engineering} ({CSE})},
	author = {Fu, Yangzhi and Yuan, Xiaochen},
	month = dec,
	year = {2020},
	keywords = {Feature extraction, Visualization, Databases, Composite Feature Extraction, Emotion recognition, Neurogram Features, Noise measurement, Paralinguistic and Prosodic Features, Speech Emotion Classification, Speech recognition, Support Vector Machine, Two dimensional displays},
	pages = {72--77},
	file = {Fu_Yuan_2020_Composite Feature Extraction for Speech Emotion Recognition.pdf:/Users/maodou/Zotero/storage/AILWLVA3/Fu_Yuan_2020_Composite Feature Extraction for Speech Emotion Recognition.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/KWTX8FE5/9345919.html:text/html},
}

@inproceedings{liu_image_2020,
	title = {Image {Self}-{Recovery} {Based} on {Authentication} {Feature} {Extraction}},
	doi = {10.1109/TrustCom50675.2020.00164},
	abstract = {This paper proposes a novel image self-recovery scheme based on authentication feature extraction. The Authentication Feature Extraction method is proposed to calculate the authentication information. The Set Partitioning in Hierarchical Trees encoding algorithm is employed to calculate the recovery information. Moreover, in order to retrieve the damaged information caused by tampering, we propose to map each block into another position and generate the mapped-recovery information accordingly. In this way, a double assurance of recovery information can be provided. Experimental results show the superior performance of the proposed scheme in terms of image self-recovery. Comparison with the state-of-the-art works demonstrate that the proposed scheme shows efficiency in strong capability for image recovery, and effectiveness of attack resistance.},
	booktitle = {2020 {IEEE} 19th {International} {Conference} on {Trust}, {Security} and {Privacy} in {Computing} and {Communications} ({TrustCom})},
	author = {Liu, Tong and Yuan, Xiaochen},
	month = dec,
	year = {2020},
	note = {ISSN: 2324-9013},
	keywords = {Feature extraction, Watermarking, Authentication, Encoding, Authentication Feature Extraction, Authentication Information, Image Self-Recovery, Partitioning algorithms, Privacy, Recovery Information, Resistance, Set Partitioning in Hierarchical Trees},
	pages = {1222--1227},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/F5ADPE2E/9343106.html:text/html;Liu_Yuan_2020_Image Self-Recovery Based on Authentication Feature Extraction.pdf:/Users/maodou/Zotero/storage/JG5AW9QH/Liu_Yuan_2020_Image Self-Recovery Based on Authentication Feature Extraction.pdf:application/pdf},
}

@inproceedings{yuan_dual_2021,
	address = {Sanya China},
	title = {Dual {Partial} {Recurrent} {Networks} for {Hyperspectral} {Image} {Change} {Detection}},
	isbn = {978-1-4503-8505-3},
	url = {https://dl.acm.org/doi/10.1145/3508546.3508616},
	doi = {10.1145/3508546.3508616},
	abstract = {This paper presents a Dual Partial Recurrent Networks (DUALPRNs) which can project more accurate and effective image features by learning invariant pixel pairs with high confidence. The Change Vector Analysis provides a reference for the model to select invariant pixel pairs with high confidence as training samples. Then, the Unsupervised Slow Feature Analysis (USFA) is utilized to suppress the invariant pixel features projected by DUAL-PRNs, and highlight the variant pixel features, respectively. Thus, more obvious discrimination between the invariant and variant pixels can be achieved. Two groups of features are then obtained by passing bi-temporal remote sensing images through DUAL-PRNs and USFA. Chi-square distance is employed to calculate the divergence between two groups of features and thus generate the Change Intensity Map. Finally, the thresholding algorithm transforms the change intensity map into binary change map. Experimental results show that the proposed change detection model DUAL-PRNs performs better than the advanced model DSFA-128-2.},
	language = {en},
	urldate = {2022-11-01},
	booktitle = {2021 4th {International} {Conference} on {Algorithms}, {Computing} and {Artificial} {Intelligence}},
	publisher = {ACM},
	author = {Yuan, Xiaochen and Li, Jinlong},
	month = dec,
	year = {2021},
	pages = {1--7},
	file = {Yuan 和 Li - 2021 - Dual Partial Recurrent Networks for Hyperspectral .pdf:/Users/maodou/Zotero/storage/IPKJMQWE/Yuan 和 Li - 2021 - Dual Partial Recurrent Networks for Hyperspectral .pdf:application/pdf},
}

@inproceedings{yuan_reversible_2022,
	title = {Reversible {Multi}-{Level} {Watermarking} {Scheme} for {Color} {Images}},
	doi = {10.1109/ICEIEC54567.2022.9835083},
	abstract = {Reversible data hiding is to embed data into digital multimedia, while the original multimedia and embedded data can be restored from the watermarked one without any loss. In this paper, we propose a novel Reversible Multi-Level Watermarking (RMLW) scheme for color images with grayscale invariance. Being different from the traditional reversible data hiding methods, we adapt the gray scale-invariant reversible watermarking method which keeps the grayscale of image unchanged as the information is embedded. In the RMLW, one feature region of high robustness is extracted and into which the watermarks are then embedded for multiple times. Lots of experiments have been conducted and the results show that the proposed scheme can extend the capacity efficiently while keep the characteristic of grayscale invariance.},
	booktitle = {2022 {IEEE} 12th {International} {Conference} on {Electronics} {Information} and {Emergency} {Communication} ({ICEIEC})},
	author = {Yuan, Xiaochen and Sun, Ying},
	month = jul,
	year = {2022},
	note = {ISSN: 2377-844X},
	keywords = {Feature extraction, Robustness, Watermarking, Color, Gray-scale, Histograms, Conferences, Gray scale-invariant, Reversible data hiding, Reversible Multi-Level Watermarking (RMLW)},
	pages = {9--12},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/U8BSVQ7I/9835083.html:text/html;Yuan_Sun_2022_Reversible Multi-Level Watermarking Scheme for Color Images.pdf:/Users/maodou/Zotero/storage/GPTYH8YR/Yuan_Sun_2022_Reversible Multi-Level Watermarking Scheme for Color Images.pdf:application/pdf},
}

@inproceedings{zhang_recognition_2022,
	title = {Recognition of {Score} {Word} in {Freestyle} {Kayaking}},
	doi = {10.1109/ICEIEC54567.2022.9835045},
	abstract = {Speech is the most natural information carrier for human beings, and it is likely to become the main way of human-computer interaction in the future. This paper presents an isolated score word recognition method using Mel-scale Frequency Cepstral Coefficients (MFCC) and Dynamic Time Warping (DTW). The processing stage of the speech signal is the basic stage of the speech recognition system, to analyze the speech signal and convert it into speech feature parameters. An endpoints detection method is proposed using the joint adjustment of short-term energy and zero-crossing rate. It can better detect the endpoints, and directly improve the accuracy of subsequent work. On this basis, the MFCC feature is then extracted from the preprocessed speech signal, and the DTW pattern matching is applied to the extracted features. In the experiments, speeches from multiple speakers were collected, each with a specific freestyle kayak action word. The results show that this method has better performance comparing with the existing methods.},
	booktitle = {2022 {IEEE} 12th {International} {Conference} on {Electronics} {Information} and {Emergency} {Communication} ({ICEIEC})},
	author = {Zhang, Qiyuan and Yuan, Xiaochen and Lam, Chan Tong},
	month = jul,
	year = {2022},
	note = {ISSN: 2377-844X},
	keywords = {Feature extraction, Training, Time-frequency analysis, Databases, Conferences, Speech recognition, Dynamic Time Warping, End Point Detection, Freestyle Kayaking, Human computer interaction, Mel-scale Frequency Cepstral Coefficients},
	pages = {67--70},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/ALNX7UAX/9835045.html:text/html;Zhang et al_2022_Recognition of Score Word in Freestyle Kayaking.pdf:/Users/maodou/Zotero/storage/8RLQF5JB/Zhang et al_2022_Recognition of Score Word in Freestyle Kayaking.pdf:application/pdf},
}

@inproceedings{yuan_halftoning-based_2022,
	title = {Halftoning-{Based} {Fragile} {Watermarking} {Approach} for {Digital} {Image} {Self}-{Recovery}},
	doi = {10.1109/ICSIP55141.2022.9886130},
	abstract = {This paper proposes a halftoning-based fragile watermarking approach for digital image tamper detection and self-recovery. The Set Partitioning in Hierarchical Trees (SPIHT) algorithm and halftoning technique are employed to generate the primary recovery bits and secondary recovery bits, respectively. On basis of that, the authentication bits are generated. The Arnold Cat Map and diagonal mapping are then applied to further improve the accuracy of tamper detection and ensure the quality of self-recovery. The experimental results have been conducted to demonstrate the superiorities of the proposed approach in imperceptibility and recovery capability.},
	booktitle = {2022 7th {International} {Conference} on {Signal} and {Image} {Processing} ({ICSIP})},
	author = {Yuan, Xiaochen and Zhang, Qiyuan},
	month = jul,
	year = {2022},
	keywords = {Digital images, Watermarking, Authentication, Partitioning algorithms, tamper detection, Arnold cat map, halftoning technique, Image processing, Set Partitioning in Hierarchical Trees (SPIHT)},
	pages = {352--355},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/XNGIJC5T/9886130.html:text/html;Yuan_Zhang_2022_Halftoning-Based Fragile Watermarking Approach for Digital Image Self-Recovery.pdf:/Users/maodou/Zotero/storage/UAG6QAHC/Yuan_Zhang_2022_Halftoning-Based Fragile Watermarking Approach for Digital Image Self-Recovery.pdf:application/pdf},
}

@article{pun_geometric_2010,
	title = {Geometric {Invariant} {Digital} {Image} {Watermarking} {Scheme} {Based} on {Histogram} in {DWT} {Domain}},
	volume = {5},
	doi = {10.4304/jmm.5.5.434-442},
	abstract = {A robust and geometric invariant digital watermarking scheme for gray-level images is proposed in this paper. The scheme carries out watermark embedding and extraction based on histogram in DWT domain. For watermark embedding, firstly, the original image is decomposed into the approximation and details sub-bands, of which, the approximation sub-band is used for watermark embedding. Pixels of the approximation subband are grouped into m blocks, each of which has the same number of gray-levels, thus the block histogram is generated; with the block histogram, the percentage of number of pixels in each block is calculated. Then some pixels in a block are moved to form a specific pattern in the gray-level histogram distribution, indicating the watermark. Finally, the embedded approximation sub-band and the other three details sub-bands are constructed into a watermarked image. For watermark extraction, firstly, the watermarked image is also decomposed into the approximation and details sub-bands; then the pixels in the approximation sub-band are grouped into blocks in the similar manner. According to the histogram distribution in each block, the watermark is extracted. Experimental results show that the proposed scheme is highly robust against JPEG compression, geometric attacks and some common signal processing, and it outperforms the existing methods in term of robustness.},
	journal = {Journal of Multimedia},
	author = {Pun, Chi-Man and Yuan, Xiaochen},
	month = oct,
	year = {2010},
	pages = {434--442},
}

@article{pun_robust_2010,
	title = {Robust and geometric invariant watermarking scheme using block and gray-level histograms},
	author = {Pun, C.-M. and Yuan, X.-C.},
	year = {2010},
	note = {ISBN: 1975-9339},
}

@article{yuan_geometrically_2012,
	title = {Geometrically invariant image watermarking based on feature extraction and {Zernike} transform},
	volume = {6},
	number = {2},
	journal = {International Journal of Security and its Applications},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	year = {2012},
	note = {ISBN: 1738-9976},
	pages = {217--222},
}

@article{YUAN20132087,
	title = {Geometric invariant watermarking by local {Zernike} moments of binary image patches},
	volume = {93},
	issn = {0165-1684},
	url = {https://www.sciencedirect.com/science/article/pii/S0165168413000418},
	doi = {https://doi.org/10.1016/j.sigpro.2013.01.024},
	abstract = {A novel digital image watermarking scheme based on feature extraction and local Zernike transform is proposed in this paper. We proposed a local Zernike moments based watermarking scheme where the watermarked image/region can be obtained directly by inverse Zernike Transform. An edge-based feature detector is proposed for local region extraction, with which, the distinct circular patch of given size can be extracted for watermark embedding and extraction. The extracted circular patch is decomposed into a collection of binary patches and Zernike transform is applied to the selected binary patches. Magnitudes of the local Zernike moments are calculated and modified to embed the watermarks. Experimental results show that the proposed watermarking scheme is very robust against geometric distortion such as rotation, scaling, cropping, and affine transformation; and common signal processing such as JPEG compression, median filtering, and low-pass Gaussian filtering.},
	number = {7},
	journal = {Signal Processing},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man and Chen, C.-L. Philip},
	year = {2013},
	keywords = {Feature extraction, Edge-based feature detector, Inverse Zernike transform, Local Zernike transform},
	pages = {2087--2095},
}

@article{pun_robust_2013,
	title = {Robust {Segments} {Detector} for {De}-{Synchronization} {Resilient} {Audio} {Watermarking}},
	volume = {21},
	issn = {1558-7924},
	doi = {10.1109/TASL.2013.2279312},
	abstract = {A robust feature points detector for invariant audio watermarking is proposed in this paper. The audio segments centering at the detected feature points are extracted for both watermark embedding and extraction. These feature points are invariant to various attacks and will not be changed much for maintaining high auditory quality. Besides, high robustness and inaudibility can be achieved by embedding the watermark into the approximation coefficients of Stationary Wavelet Transform (SWT) domain, which is shift invariant. The spread spectrum communication technique is adopted to embed the watermark. Experimental results show that the proposed Robust Audio Segments Extractor (RASE) and the watermarking scheme are not only robust against common audio signal processing, such as low-pass filtering, MP3 compression, echo addition, volume change, and normalization; and distortions introduced in Stir-mark benchmark for Audio; but also robust against synchronization geometric distortions simultaneously, such as resample time-scale modification (TSM) with scaling factors up to ±50\%, pitch invariant TSM by ±50\%, and tempo invariant pitch shifting by ±50\%. In general, the proposed scheme can well resist various attacks by the joint RASE and SWT approach, which performs much better comparing with the existing state-of-the art methods.},
	number = {11},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Pun, Chi-Man and Yuan, Xiao-Chen},
	month = nov,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Audio, Speech, and Language Processing},
	keywords = {Feature extraction, Robustness, Watermarking, Synchronization, Distortion, Digital audio players, pitch shifting, Robust audio segments extractor (RASE), stationary wavelet transform (SWT), synchronization geometric distortions, time-scale modification (TSM)},
	pages = {2412--2424},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/6A9FDNPW/6583994.html:text/html;Pun_Yuan_2013_Robust Segments Detector for De-Synchronization Resilient Audio Watermarking.pdf:/Users/maodou/Zotero/storage/42RGCKTQ/Pun_Yuan_2013_Robust Segments Detector for De-Synchronization Resilient Audio Watermarking.pdf:application/pdf},
}

@article{pun_histogram_2015,
	title = {Histogram modification based image watermarking resistant to geometric distortions},
	volume = {74},
	number = {18},
	journal = {Multimedia Tools and Applications},
	author = {Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2015},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {7821--7842},
}

@article{yuan_feature_2014,
	title = {Feature extraction and local {Zernike} moments based geometric invariant watermarking},
	volume = {72},
	number = {1},
	journal = {Multimedia tools and applications},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	year = {2014},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {777--799},
}

@article{YUAN2015159,
	title = {Robust {Mel}-{Frequency} {Cepstral} coefficients feature detection and dual-tree complex wavelet transform for digital audio watermarking},
	volume = {298},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S002002551401130X},
	doi = {https://doi.org/10.1016/j.ins.2014.11.040},
	abstract = {A novel digital audio watermarking scheme based on robust Mel-Frequency Cepstral coefficients feature detection and dual-tree complex wavelet transform is proposed in this paper, which is similar as patchwork based methods that several segments are extracted from the host audio clip for watermarking use. The robust Mel-Frequency Cepstral coefficients feature detection method is proposed to extract the feature segments which should be relocated when the host audio signal attacked by various distortions including both the common audio signal processing and the conventional geometric distortions. With the robust feature segments, the approximate shift invariant transform dual-tree complex wavelet transform based watermarking method is proposed to embed the watermark into the DT CWT real low-pass coefficients of each segment, using the spread spectrum techniques. The linear correlation is calculated to judge the existence of the watermark during the watermark detection. Experimental results show that the proposed digital audio watermarking scheme based on robust Mel-Frequency Cepstral coefficients feature detection and dual-tree complex wavelet transform can achieve high robustness against the common audio signal processing, such as low-pass filtering, MP3 compression, echo addition, volume change, and normalization; and geometric distortions, such as resample Time-Scale Modification (TSM), pitch invariant TSM, and tempo invariant pitch shifting. In addition, the proposed audio watermarking scheme is resilient to Stir-mark for Audio, and it performs much better comparing with the existing state-of-the art methods.},
	journal = {Information Sciences},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man and Philip Chen, C.L.},
	year = {2015},
	keywords = {Dual-Tree Complex Wavelet Transform (DT CWT), Mel-Frequency Cepstral Coefficients, Pitch shifting, Stir-mark, Time-Scale Modification (TSM)},
	pages = {159--179},
}

@article{pun_image_2015,
	title = {Image {Forgery} {Detection} {Using} {Adaptive} {Oversegmentation} and {Feature} {Point} {Matching}},
	volume = {10},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2015.2423261},
	abstract = {A novel copy-move forgery detection scheme using adaptive oversegmentation and feature point matching is proposed in this paper. The proposed scheme integrates both block-based and keypoint-based forgery detection methods. First, the proposed adaptive oversegmentation algorithm segments the host image into nonoverlapping and irregular blocks adaptively. Then, the feature points are extracted from each block as block features, and the block features are matched with one another to locate the labeled feature points; this procedure can approximately indicate the suspected forgery regions. To detect the forgery regions more accurately, we propose the forgery region extraction algorithm, which replaces the feature points with small superpixels as feature blocks and then merges the neighboring blocks that have similar local color features into the feature blocks to generate the merged regions. Finally, it applies the morphological operation to the merged regions to generate the detected forgery regions. The experimental results indicate that the proposed copy-move forgery detection scheme can achieve much better detection results even under various challenging conditions compared with the existing state-of-the-art copy-move forgery detection methods.},
	number = {8},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Pun, Chi-Man and Yuan, Xiao-Chen and Bi, Xiu-Li},
	month = aug,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Forgery, Digital images, Feature extraction, Image color analysis, Image segmentation, Copy-move forgery detection, Discrete wavelet transforms, adaptive over-segmentation, Adaptive Over-Segmentation, Copy-Move Forgery Detection, forgery region extraction, Forgery Region Extraction, local color feature, Local Color Feature},
	pages = {1705--1716},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/964UJLNB/7086315.html:text/html;Pun et al_2015_Image Forgery Detection Using Adaptive Oversegmentation and Feature Point.pdf:/Users/maodou/Zotero/storage/NST8Z3HL/Pun et al_2015_Image Forgery Detection Using Adaptive Oversegmentation and Feature Point.pdf:application/pdf},
}

@article{YAN20161,
	title = {Multi-scale image hashing using adaptive local feature extraction for robust tampering detection},
	volume = {121},
	issn = {0165-1684},
	url = {https://www.sciencedirect.com/science/article/pii/S0165168415003709},
	doi = {https://doi.org/10.1016/j.sigpro.2015.10.027},
	abstract = {The main problem addressed in this paper is the robust tampering detection of the image received in a transmission under various content-preserving attacks. To this aim the multi-scale image hashing method is proposed by using the location-context information of the features generated by adaptive and local feature extraction techniques. The generated hash is attached to the image before transmission and analyzed at destination to filter out the geometric transformations occurred in the received image by image restoration firstly. Based on the restored image, the image authentication using the global and color hash component is performed to determine whether the received image has the same contents as the trusted one or has been maliciously tampered, or just different. After regarding the received image as being tampered, the tampered regions will be localized through the multi-scale hash component. Lots of experiments are conducted to indicate that our tampering detection scheme outperforms the existing state-of-the-art methods and is very robust against the content-preserving attacks, including both common signal processing and geometric distortions.},
	journal = {Signal Processing},
	author = {Yan, Cai-Ping and Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2016},
	keywords = {Adaptive Feature Point Detection, Image authentication, Multi-scale image hashing, Tampering detection},
	pages = {1--16},
}

@article{BI2016226,
	title = {Multi-level dense descriptor and hierarchical feature matching for {Copy}–{Move} forgery detection},
	volume = {345},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025516000955},
	doi = {https://doi.org/10.1016/j.ins.2016.01.061},
	abstract = {In this paper, a Multi-Level Dense Descriptor (MLDD) extraction method and a Hierarchical Feature Matching method are proposed to detect copy–move forgery in digital images. The MLDD extraction method extracts the dense feature descriptors using multiple levels, while the extracted dense descriptor consists of two parts: the Color Texture Descriptor and the Invariant Moment Descriptor. After calculating the MLDD for each pixel, the Hierarchical Feature Matching method subsequently detects forgery regions in the input image. First, the pixels that have similar color textures are grouped together into distinctive neighbor pixel sets. Next, each pixel is matched with pixels in its corresponding neighbor pixel set through its geometric invariant moments. Then, the redundant pixels from previously generated matched pixel pairs are filtered out by the proposed Adaptive Distance and Orientation Based Filtering method. Finally, some morphological operations are applied to generate the final detected forgery regions. Experimental results show that the proposed scheme can achieve much better detection results compared with the existing state-of-the-art CMFD methods, even under various challenging conditions such as geometric transforms, JPEG compression, noise addition and down-sampling.},
	journal = {Information Sciences},
	author = {Bi, Xiuli and Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2016},
	keywords = {Color Texture Descriptor, Copy–Move Forgery Detection (CMFD), Hierarchical Feature Matching, Invariant Moment Descriptor, Multi-Level Dense Descriptor (MLDD)},
	pages = {226--242},
}

@article{PUN2016195,
	title = {Multi-scale noise estimation for image splicing forgery detection},
	volume = {38},
	issn = {1047-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S1047320316300098},
	doi = {https://doi.org/10.1016/j.jvcir.2016.03.005},
	abstract = {Noise discrepancies in multiple scales are utilized as indicators for image splicing forgery detection in this paper. Specifically, the test image is initially segmented into superpixels of multiple scales. In each individual scale, noise level function, which reflects the relation between noise level and brightness of each segment, is computed. Those segments not constrained by the noise level function are regarded as suspicious regions. In the final step, pixels appears in suspicious regions of each scale, after necessary morphological processing, are marked as spliced region(s). The Optimal Parameter Combination Searching (OPCS) Algorithm is proposed to determine the optimal parameters during the process. Two datasets are created for training the optimal parameters and to evaluate the proposed scheme, respectively. The experimental results show that the proposed scheme is effective, especially for the multi-objects splicing. In addition, the proposed scheme is proven to be superior to the existing state-of-the-art method.},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Pun, Chi-Man and Liu, Bo and Yuan, Xiao-Chen},
	year = {2016},
	keywords = {Multi-scale noise estimation, Noise level function, Optimal Parameter Combination Searching (OPCS), SLIC superpixels, Splicing forgery},
	pages = {195--206},
}

@article{yan_quaternion-based_2016,
	title = {Quaternion-{Based} {Image} {Hashing} for {Adaptive} {Tampering} {Localization}},
	volume = {11},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2016.2594136},
	abstract = {Image-hashing-based tampering detection methods have been widely studied with continuous advancements. However, most of existing models are designed for a specific tampering. In this paper, we propose a novel quaternion-based image hashing to detect almost all types of tampering, including color changing, copy move, splicing, and so on. First, the quaternion Fourier-Mellin transform is used to calculate the geometric hash to eliminate the influence of geometric distortions. Then, a new quaternion image construction method, which combines advantages of both color and structural features, is proposed to implement the quaternion Fourier transform to calculate the image feature hash to locate the tampered regions. The objective is to provide a reasonably short image hashing with good performance, i.e., being perceptually robust against various content-preserving attacks while capable of detecting and locating almost all types of tampering. Furthermore, an adaptive tampering localization algorithm is proposed based on clustering analysis to improve the detection accuracy. The experimental results show that the proposed tampering detection model outperforms the existing state-of-the-art models and is very robust against various content-preserving attacks.},
	number = {12},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Yan, Cai-Ping and Pun, Chi-Man and Yuan, Xiao-Chen},
	month = dec,
	year = {2016},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Feature extraction, Image color analysis, Robustness, Splicing, Authentication, Transforms, Quaternions, adaptive tampering localization, Image hashing, quaternion Fourier transform (QFT), quaternion Fourier-Mellin transform (QMMT)},
	pages = {2664--2677},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/KB5UBD32/7523392.html:text/html;Yan et al_2016_Quaternion-Based Image Hashing for Adaptive Tampering Localization.pdf:/Users/maodou/Zotero/storage/XK4E3SH6/Yan et al_2016_Quaternion-Based Image Hashing for Adaptive Tampering Localization.pdf:application/pdf},
}

@article{pun_robust_2018,
	title = {Robust image hashing using progressive feature selection for tampering detection},
	volume = {77},
	number = {10},
	journal = {Multimedia Tools and Applications},
	author = {Pun, Chi-Man and Yan, Cai-Ping and Yuan, Xiao-Chen},
	year = {2018},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {11609--11633},
}

@article{pun_image_2017,
	title = {Image {Alignment}-{Based} {Multi}-{Region} {Matching} for {Object}-{Level} {Tampering} {Detection}},
	volume = {12},
	issn = {1556-6013, 1556-6021},
	url = {http://ieeexplore.ieee.org/document/7583645/},
	doi = {10.1109/TIFS.2016.2615272},
	abstract = {Tampering detection methods based on image hashing have been widely studied with continuous advancements. However, most existing models cannot generate object-level tampering localization results, because the forensic hashes attached to the image lack contour information. In this paper, we present a novel tampering detection model that can generate an accurate, object-level tampering localization result. First, an adaptive image segmentation method is proposed to segment the image into closed regions based on strong edges. Then, the color and position features of the closed regions are extracted as a forensic hash. Furthermore, a geometric invariant tampering localization model named image alignment-based multi-region matching (IAMRM) is proposed to establish the region correspondence between the received and forensic images by exploiting their intrinsic structure information. The model estimates the parameters of geometric transformations via a robust image alignment method based on triangle similarity; in addition, it matches multiple regions simultaneously by utilizing manifold ranking based on different graph structures and features. Experimental results demonstrate that the proposed IAMRM is a promising method for object-level tampering detection compared with the state-ofthe-art methods.},
	language = {en},
	number = {2},
	urldate = {2022-10-28},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Pun, Chi-Man and Yan, Caiping and Yuan, Xiao-Chen},
	month = feb,
	year = {2017},
	pages = {377--391},
	file = {Pun 等。 - 2017 - Image Alignment-Based Multi-Region Matching for Ob.pdf:/Users/maodou/Zotero/storage/GG3ED2K5/Pun 等。 - 2017 - Image Alignment-Based Multi-Region Matching for Ob.pdf:application/pdf},
}

@article{bi_multi-scale_2018,
	title = {Multi-scale feature extraction and adaptive matching for copy-move forgery detection},
	volume = {77},
	number = {1},
	journal = {Multimedia Tools and Applications},
	author = {Bi, XiuLi and Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2018},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {363--385},
}

@article{han_regframe_2018,
	title = {{RegFrame}: fast recognition of simple human actions on a stand-alone mobile device},
	volume = {30},
	number = {9},
	journal = {Neural Computing and Applications},
	author = {Han, Di and Li, Jianqing and Zeng, Zihua and Yuan, Xiaochen and Li, Wenting},
	year = {2018},
	note = {ISBN: 1433-3058
Publisher: Springer},
	pages = {2787--2793},
}

@article{zhao_ida-net_2023,
	title = {{IDA}-{Net}: {Inheritable} {Deformable} {Attention} {Network} of structural {MRI} for {Alzheimer}’s {Disease} {Diagnosis}},
	volume = {84},
	issn = {1746-8094},
	shorttitle = {{IDA}-{Net}},
	url = {https://www.sciencedirect.com/science/article/pii/S1746809423002203},
	doi = {10.1016/j.bspc.2023.104787},
	abstract = {To precisely diagnose neurological diseases, such as Alzheimer’s disease, clinicians need to observe the microstructural changes of local brain atrophy with the help of structural magnetic resonance image (sMRI). Some Convolutional Neural Networks (CNNs) have recently achieved excellent performance in auxiliary clinicians to provide the diagnosis suggestion. However, there still exist several challenges. Foremost, several researchers manually predefine some regions of interest (ROIs) as the input of the CNN-based networks, which impedes the model’s robustness and interpretability of clinical applications. Second, since the position relevance of pathological features interferes with the surrounding tissue regions in ROIs, it is hard for the current CNN-based networks to extract the microstructural changes of these ROIs precisely. To address the above challenges, we optimize the Transformer structure for Alzheimer’s Disease Diagnosis and propose an Inheritable Deformable Attention Network (IDA-Net). Specifically, the IDA-Net mainly comprises the 3D Deformable Self-Attention module and the Inheritable 3D Deformable Self-Attention module. The 3D Deformable Self-Attention module can automatically adjust the position and scale of the selected patches according to the structural changes in sMRI. Furthermore, the Inheritable 3D Deformable Self-Attention module can locate and output relatively important regions with discriminative features in sMRI, which can assist physicians in the clinical diagnosis. Our proposed IDA-Net method is evaluated on the sMRI of 2813 subjects from ADNI and AIBL datasets. The results show that our IDA-Net method behaves better than several state-of-the-art methods in classification performance and model generalization.},
	language = {en},
	urldate = {2023-03-21},
	journal = {Biomedical Signal Processing and Control},
	author = {Zhao, Qin and Huang, Guoheng and Xu, Pingping and Chen, Ziyang and Li, Wenyuan and Yuan, Xiaochen and Zhong, Guo and Pun, Chi-Man and Huang, Zhixin},
	month = jul,
	year = {2023},
	keywords = {Deep learning, Alzheimer’s Disease Diagnosis, Computer-aided diagnosis, Deformation, Inheritance, Self-attention, Structural magnetic resonance image, Transformer},
	pages = {104787},
	file = {ScienceDirect Snapshot:/Users/maodou/Zotero/storage/8RCSPVLK/S1746809423002203.html:text/html},
}

@article{lin_quaternion_2023,
	title = {Quaternion attention multi-scale widening network for endoscopy image super-resolution},
	issn = {0031-9155},
	url = {http://iopscience.iop.org/article/10.1088/1361-6560/acc002},
	doi = {10.1088/1361-6560/acc002},
	abstract = {Objective. In the field of endoscopic imaging, Super-Resolution (SR) plays an important role in Manufactured Diagnosis, physicians and machine Automatic Diagnosis. Although many recent studies have been performed, by using deep convolutional neural networks on endoscopic Super-Resolution, most of the methods have large parameters, which limits their practical application. In addition, almost all of these methods treat each channel equally based on the real-valued domain, without considering the difference among the different channels. Our objective is to design a super-resolution model named Quaternion Attention Multi-scale Widening Network (QAMWN) for endoscopy images to address the above problem. Approach. QAMWN contains a stacked Quaternion Attention Multi-Scale Widening Block (QAMWB), that composed of Multi-Scale Feature Widening Aggregation Module (MFWAM) and Quaternion Residual Channel Attention (QRCA). The MFWAM adopts multi-scale architecture with step-wise widening on feature channels for better feature extraction; and in QRCA, quaternion is introduced to construct Residual Channel Attention Mechanism, which obtains adaptively scales features by considering compact cross channel interactions in the hyper-complex domain. Main results. To verify the efficacy of our method, it is performed on two public endoscopic datasets, CVC ClinicDB and Kvasir dataset. The experimental results show that our proposed method can achieve a better trade-off in model size and performance. More importantly, the proposed QAMWN outperforms previous state-of-the-art methods in both metrics and visualization. Significance. We propose a lightweight super-resolution network for endoscopy and achieves better performance with fewer parameters, which helps in clinical diagnosis of endoscopy.},
	language = {en},
	urldate = {2023-03-21},
	journal = {Physics in Medicine \& Biology},
	author = {Lin, Junyu and Huang, Guoheng and Huang, Jun and Yuan, Xiaochen and Zeng, Yiwen and Shi, Cheng},
	year = {2023},
}

@article{bao_point_2023,
	title = {Point {Cloud} {Plane} {Segmentation}-{Based} {Robust} {Image} {Matching} for {Camera} {Pose} {Estimation}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/15/2/497},
	doi = {10.3390/rs15020497},
	abstract = {The mainstream image matching method for recovering the motion of the camera is based on local feature matching, which faces the challenges of rotation, illumination, and the presence of dynamic objects. In addition, local feature matching relies on the distance between descriptors, which easily leads to lots of mismatches. In this paper, we propose a new robust image matching method for camera pose estimation, called IM\_CPE. It is a novel descriptor matching method combined with 3-D point clouds for image matching. Specifically, we propose to extract feature points based on a pair of matched point cloud planes, which are generated and segmented based on depth images. Then, the feature points are matched based on the distance between their corresponding 3-D points on the point cloud planes and the distance between their descriptors. Moreover, the robustness of the matching can be guaranteed by the centroid distance of the matched point cloud planes. We evaluate the performance of IM\_CPE using four well-known key point extraction algorithms, namely Scale-Invariant Feature Transform (SIFT), Speed Up Robust Feature (SURF), Features from Accelerated Segment Test (FAST), and Oriented FAST and Rotated Brief (ORB), with four sequences from the TUM RGBD dataset. According to the experimental results, compared to the original SIFT, SURF, FAST, and ORB algorithms, the NN\_mAP performance of the four key point algorithms has been improved by 11.25\%, 13.98\%, 16.63\%, and 10.53\% on average, respectively, and the M.Score has also been improved by 25.15\%, 23.05\%, 22.28\%, and 11.05\% on average, respectively. The results show that the IM\_CPE can be combined with the existing key points extraction algorithms and the IM\_CPE can significantly improve the performance of these key points algorithms.},
	language = {en},
	number = {2},
	urldate = {2023-03-21},
	journal = {Remote Sensing},
	author = {Bao, Junqi and Yuan, Xiaochen and Huang, Guoheng and Lam, Chan-Tong},
	month = jan,
	year = {2023},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {camera pose estimation, image matching, image segmentation, key points extraction, point cloud},
	pages = {497},
	file = {Full Text PDF:/Users/maodou/Zotero/storage/446U6UJ8/Bao 等 - 2023 - Point Cloud Plane Segmentation-Based Robust Image .pdf:application/pdf},
}

@article{han_weakly_2023,
	title = {Weakly supervised semantic segmentation of histological tissue via attention accumulation and pixel-level contrast learning},
	volume = {68},
	issn = {0031-9155},
	url = {https://dx.doi.org/10.1088/1361-6560/acaeee},
	doi = {10.1088/1361-6560/acaeee},
	abstract = {Objective. Histopathology image segmentation can assist medical professionals in identifying and diagnosing diseased tissue more efficiently. Although fully supervised segmentation models have excellent performance, the annotation cost is extremely expensive. Weakly supervised models are widely used in medical image segmentation due to their low annotation cost. Nevertheless, these weakly supervised models have difficulty in accurately locating the boundaries between different classes of regions in pathological images, resulting in a high rate of false alarms Our objective is to design a weakly supervised segmentation model to resolve the above problems. Approach. The segmentation model is divided into two main stages, the generation of pseudo labels based on class residual attention accumulation network (CRAANet) and the semantic segmentation based on pixel feature space construction network (PFSCNet). CRAANet provides attention scores for each class through the class residual attention module, while the Attention Accumulation (AA) module overlays the attention feature maps generated in each training epoch. PFSCNet employs a network model containing an inflated convolutional residual neural network and a multi-scale feature-aware module as the segmentation backbone, and proposes dense energy loss and pixel clustering modules are based on contrast learning to solve the pseudo-labeling-inaccuracy problem. Main results. We validate our method using the lung adenocarcinoma (LUAD-HistoSeg) dataset and the breast cancer (BCSS) dataset. The results of the experiments show that our proposed method outperforms other state-of-the-art methods on both datasets in several metrics. This suggests that it is capable of performing well in a wide variety of histopathological image segmentation tasks. Significance. We propose a weakly supervised semantic segmentation network that achieves approximate fully supervised segmentation performance even in the case of incomplete labels. The proposed AA and pixel-level contrast learning also make the edges more accurate and can well assist pathologists in their research.},
	language = {en},
	number = {4},
	urldate = {2023-03-21},
	journal = {Physics in Medicine \& Biology},
	author = {Han, Yongqi and Cheng, Lianglun and Huang, Guoheng and Zhong, Guo and Li, Jiahua and Yuan, Xiaochen and Liu, Hongrui and Li, Jiao and Zhou, Jian and Cai, Muyan},
	month = feb,
	year = {2023},
	note = {Publisher: IOP Publishing},
	pages = {045010},
}

@inproceedings{bao_robust_2023,
	address = {New York, NY, USA},
	series = {{ACAI} '22},
	title = {Robust {Image} {Matching} for {Camera} {Pose} {Estimation} {Using} {Oriented} {Fast} and {Rotated} {Brief}},
	isbn = {978-1-4503-9833-6},
	url = {https://doi.org/10.1145/3579654.3579720},
	doi = {10.1145/3579654.3579720},
	abstract = {This paper presents a novel image matching method for camera pose estimation based on point cloud segmentation. The Oriented Fast and Rotated Brief (ORB) is employed to extract the key points, which are then extracted based on matched point cloud planes. The point cloud planes are segmented based on the depth image, and then matched by the distance of the centroid between planes. The putative corresponding key points on the planes are generated based on the distance of their 3-D coordinates and the descriptors of the key points are further matched based on the putative corresponding key points. As an additional constraint, the spatial relative position in 3-D spaces solves the problem that the descriptors of each key point in some scenarios are too similar which may lead to a mismatch. According to the experimental results, the superiority of the proposed approach is illustrated by comparing with the existing matching methods.},
	urldate = {2023-03-20},
	booktitle = {Proceedings of the 2022 5th {International} {Conference} on {Algorithms}, {Computing} and {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Bao, Junqi and Yuan, Xiaochen and Lam, Chan Tong},
	month = mar,
	year = {2023},
	keywords = {Image Matching, Image Segmentation, Oriented Fast and Rotated Brief, Point Cloud},
	pages = {1--5},
	file = {Full Text PDF:/Users/maodou/Zotero/storage/NM4DDWXG/Bao 等 - 2023 - Robust Image Matching for Camera Pose Estimation U.pdf:application/pdf},
}

@inproceedings{yuan_speech_2022,
	title = {Speech {Emotion} {Recognition} {Using} {Multi}-{Layer} {Perceptron} {Classifier}},
	doi = {10.1109/ICICN56848.2022.10006474},
	abstract = {This paper proposes a speech emotion recognition approach using the Multi-Layer Perceptron Classifier (MLP Classifier). The Mel-Frequency Cepstral Coefficients feature and openSMILE feature are respectively extracted. With the extracted features, MLP Classifier is used to classify the speech emotion. The Berlin database which contains seven emotions: happiness, anger, anxiety, fear, boredom and disgust, is used to evaluate the performance of the proposed approach. Data augmentation are furtherly employed and experimental results show that the proposed approach achieves satisfied performances. Comparisons are conducted when with data augmentation and without data augmentation, and the results indicate better performance with data augmentation.},
	booktitle = {2022 {IEEE} 10th {International} {Conference} on {Information}, {Communication} and {Networks} ({ICICN})},
	author = {Yuan, Xiaochen and Wong, Wai Pang and Lam, Chan Tong},
	month = aug,
	year = {2022},
	keywords = {Feature extraction, Databases, Mel frequency cepstral coefficient, Emotion recognition, Speech recognition, Anxiety disorders, mel-frequency cepstral coefficients, multi-layer perceptron classifier, openSMILE Feature, speech emotion recognition},
	pages = {644--648},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/DFV5CH8Q/10006474.html:text/html;IEEE Xplore Full Text PDF:/Users/maodou/Zotero/storage/5AFRNJSG/Yuan 等 - 2022 - Speech Emotion Recognition Using Multi-Layer Perce.pdf:application/pdf},
}

@article{zhang_c3mw_2023,
	title = {{C3MW}: {A} {Novel} {Comprehensive}-{Monitoring}-{Motivated} {Multi}-model {Watermarking} {Scheme} for {Tamper} {Detection} and {Self}-recovery},
	issn = {13191578},
	shorttitle = {{C3MW}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S131915782300349X},
	doi = {10.1016/j.jksuci.2023.101795},
	abstract = {In this paper, we propose a novel Comprehensive-Monitoring-Motivated Multi-model Watermarking (C3MW) Scheme for tampering region localization and self-recovery for 4K images. To generate the Comprehensive-Monitoring-Motivated Multi-model (C3M) Watermark, the MultiModel Authentication Bits Generation (MMAG) method and the Adaptive Block SignificanceBased Recovery Bits Generation (ASRG) method, are proposed. The MMAG aims to monitor the various bit-plane information for detecting the possible tampering in a more comprehensive manner. When performing image tampering detection, once one of the multiple models is triggered, the corresponding parcel will be marked as tampered. On basis of the detected regions, we propose a fine-tuning-based image recovery method, where the extracted recovery data consist of the fused Adaptive Block Significance (ABS) and bitmaps, while the calculated recovery data consist of the watermark information which is calculated from the received image. We conduct experiments on two public databases, respectively, the BOWS2 Dataset and the LIU4K-v2 Dataset. Comparisons with existing state-of-the-art works have been performed on the BOWS2 dataset, and our scheme improves the precision and F1 Score by 7.27\% and 3.30\%, respectively. It is clear from these results that our method has a better performance than others.},
	language = {en},
	urldate = {2023-10-18},
	journal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Zhang, Qiyuan and Yuan, Xiaochen and Lam, Chan-Tong and Xing, Zheng and Huang, Guoheng},
	month = oct,
	year = {2023},
	pages = {101795},
	file = {Zhang 等 - 2023 - C3MW A Novel Comprehensive-Monitoring-Motivated M.pdf:/Users/maodou/Zotero/storage/CVIK7TU9/Zhang 等 - 2023 - C3MW A Novel Comprehensive-Monitoring-Motivated M.pdf:application/pdf},
}
