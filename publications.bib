
@article{li_dual-tree_2018,
	title = {Dual-{Tree} {Complex} {Wavelet} {Transform} {Based} {Audio} {Watermarking} {Using} {Distortion}-{Compensated} {Dither} {Modulation}},
	volume = {6},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2018.2876233},
	abstract = {This paper presents a local audio watermarking method based on the dual-tree complex wavelet transform (DT CWT) and distortion-compensated dither modulation (DC-DM). Specifically, we perform DT CWT on extracted audio segment, and embed the watermark signal in the decomposed low-pass coefficients. During the embedding process, the selected coefficients are block-divided into multiple host vectors, and the watermark signal is embedded into the selected set of host vectors by the dither modulation process. During the extraction process, the DC-DM is applied to generate the statistical differences, and the minimum distance decoding is employed to extract the watermark signal. Experimental results show that the proposed method is robust against common signal processing attacks and de-synchronization attacks, such as re-quantization, resampling, MP3 compression, cropping, and so on. Comparisons with the existing methods also show the superiority of our proposed method.},
	journal = {IEEE Access},
	author = {Li, Mianjie and Yuan, Xiaochen and Li, Jianqing},
	year = {2018},
	note = {Conference Name: IEEE Access},
	keywords = {Watermarking, Discrete wavelet transforms, Continuous wavelet transforms, Distortion-compensated dither modulation (DC-DM), Dual-tree complex wavelet transform (DT CWT), Flowcharts, local audio watermarking, minimum distance decoding, Modulation},
	pages = {60834--60842},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/ZL8G3FJ8/8492419.html:text/html;Li et al_2018_Dual-Tree Complex Wavelet Transform Based Audio Watermarking Using.pdf:/Users/maodou/Zotero/storage/BXWRYKSL/Li et al_2018_Dual-Tree Complex Wavelet Transform Based Audio Watermarking Using.pdf:application/pdf},
}

@article{YUAN2018103,
	title = {Local multi-watermarking method based on robust and adaptive feature extraction},
	volume = {149},
	issn = {0165-1684},
	url = {https://www.sciencedirect.com/science/article/pii/S0165168418301051},
	doi = {https://doi.org/10.1016/j.sigpro.2018.03.007},
	abstract = {This paper proposes a local multi-watermarking method based on robust and adaptive feature extraction. The Robust and Adaptive Feature Detector based on DAISY Descriptor (RAF3D) is proposed to extract the feature regions of high robustness and stability. The multi-watermarking method is proposed to embed the multiple watermarks simultaneously into the same extracted feature region. In this way, the capacity will be flexible with either the number of feature regions or the number of watermarks. In the proposed method, the Gram–Schmidt process is applied to embed the watermarks in orthogonal spaces, which guarantees the multiple watermarks can be extracted independently. By repeatedly embedding the watermarks into the numerous feature regions, the success rate of watermark detection can be greatly strengthened. In addition, the local embedding strategy improves the imperceptibility of the watermarked image. Extensive experiments are conducted to evaluate the performance of the proposed scheme and the comparison with several existing methods demonstrate that the proposed scheme outperforms the existing methods in terms of the robustness against various attacks.},
	journal = {Signal Processing},
	author = {Yuan, Xiao-Chen and Li, Mianjie},
	year = {2018},
	keywords = {Gram–Schmidt process, Local multi-watermarking, Robust and adaptive feature detector},
	pages = {103--117},
}

@article{chen_triple-classification_2019,
	title = {Triple-{Classification} of {Respiratory} {Sounds} {Using} {Optimized} {S}-{Transform} and {Deep} {Residual} {Networks}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2903859},
	abstract = {Digital respiratory sounds provide valuable information for telemedicine and smart diagnosis in an non-invasive way of pathological detection. As the typical continuous abnormal respiratory sound, wheeze is clinically correlated with asthma or chronic obstructive lung diseases. Meanwhile, the discontinuous adventitious crackle is clinically correlated with pneumonia, bronchitis, and so on. The detection and classification of both attract many studies for decades. However, due to the contained artifacts and constrained feature extraction methods, the reliability and accuracy of the classification of wheeze, crackle, and normal sounds need significant improvement. In this paper, we propose a novel method for the identification of wheeze, crackle, and normal sounds using the optimized S-transform (OST) and deep residual networks (ResNets). First, the raw respiratory sound is processed by the proposed OST. Then, the spectrogram of OST is rescaled for the Resnet. After the feature learning and classification are fulfilled by the ResNet, the classes of respiratory sounds are recognized. Because the proposed OST highlights the features of wheeze, crackle, and respiratory sounds, and the deep residual learning generates discriminative features for better recognition, this proposed method provides reliable access for respiratory disease-related telemedicine and E-health diagnosis. The experimental results show that the proposed OST and ResNet is excellent for the multi-classification of respiratory sounds with the accuracy, sensitivity, and specificity up to 98.79\%, 96.27\% and 100\%, respectively. The comparison results of the triple-classification of respiratory sounds indicate that the proposed method outperforms the deep-learning-based ensembling convolutional neural network (CNN) by 3.23\% and the empirical mode decomposition-based artificial neural network (ANN) by 4.63\%, respectively.},
	journal = {IEEE Access},
	author = {Chen, Hai and Yuan, Xiaochen and Pei, Zhiyuan and Li, Mianjie and Li, Jianqing},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {Feature extraction, Training, Transforms, crackle and wheeze detection, Deep residual networks (ResNet), Diseases, Lung, optimized S-transform (OST), respiratory sounds classification, Spectrogram, Time-frequency analysis},
	pages = {32845--32852},
	file = {Chen et al_2019_Triple-Classification of Respiratory Sounds Using Optimized S-Transform and.pdf:/Users/maodou/Zotero/storage/NL3GFR8H/Chen et al_2019_Triple-Classification of Respiratory Sounds Using Optimized S-Transform and.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/RHXL2GPA/8663379.html:text/html},
}

@article{CHEN2019163,
	title = {Automatic multi-level in-exhale segmentation and enhanced generalized {S}-transform for wheezing detection},
	volume = {178},
	issn = {0169-2607},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260719305048},
	doi = {https://doi.org/10.1016/j.cmpb.2019.06.024},
	abstract = {Background and objective Wheezing is a common symptom of patients caused by asthma and chronic obstructive pulmonary diseases. Wheezing detection identifies wheezing lung sounds and helps physicians in diagnosis, monitoring, and treatment of pulmonary diseases. Different from the traditional way to detect wheezing sounds using digital image process methods, automatic wheezing detection uses computerized tools or algorithms to objectively and accurately assess and evaluate lung sounds. We propose an innovative machine learning-based approach for wheezing detection. The phases of the respiratory sounds are separated automatically and the wheezing features are extracted accordingly to improve the classification accuracy. Methods To enhance the features of wheezing for classification, the Adaptive Multi-Level In-Exhale Segmentation (AMIE$_{\textrm{S}}$EG) is proposed to automatically and precisely segment the respiratory sounds into inspiratory and expiratory phases. Furthermore, the Enhanced Generalized S-Transform (EGST) is proposed to extract the wheezing features. The highlighted features of wheezing improve the accuracy of wheezing detection with machine learning-based classifiers. Results To evaluate the novelty and superiority of the proposed AMIE$_{\textrm{S}}$EG and EGST for wheezing detection, we employ three machine learning-based classifiers, Support Vector Machine (SVM), Extreme Learning Machine (ELM) and K-Nearest Neighbor (KNN), with public datasets at segment level and record level respectively. According to the experimental results, the proposed method performs the best using the KNN classifier at segment level, with the measured accuracy, sensitivity, specificity as 98.62\%, 95.9\% and 99.3\% in average respectively. On the other aspect, at record level, the three classifiers perform excellent, with the accuracy, sensitivity, specificity up to 99.52\%, 100\% and 99.27\% respectively. We validate the method with public respiratory sounds dataset. Conclusion The comparison results indicate the very good performance of the proposed methods for long-term wheezing monitoring and telemedicine.},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Chen, Hai and Yuan, Xiaochen and Li, Jianqing and Pei, Zhiyuan and Zheng, Xiaobin},
	year = {2019},
	keywords = {Adaptive Multi-Level In-Exhale Segmentation (AMIE$_{\textrm{S}}$EG), Enhanced Generalized S Transform, Feature enhancement, Wheezing detection},
	pages = {163--173},
}

@article{yuan_gramschmidt_2020,
	title = {Gram–{Schmidt} {Orthogonalization}-{Based} {Audio} {Multiple} {Watermarking} {Scheme}},
	volume = {39},
	number = {8},
	journal = {Circuits, Systems, and Signal Processing},
	author = {Yuan, Xiaochen and Li, Mianjie},
	year = {2020},
	note = {ISBN: 1531-5878
Publisher: Springer},
	pages = {3958--3977},
}

@article{li_quaternion_2020,
	title = {Quaternion {Discrete} {Fourier} {Transform}-{Based} {Color} {Image} {Watermarking} {Method} {Using} {Quaternion} {QR} {Decomposition}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.2987914},
	abstract = {In this paper, a new Quaternion Discrete Fourier Transform (QDFT)-based digital color image watermarking method is presented. In addition, the Quaternion QR (QQR) decomposition is applied in digital watermarking technology for the first time. First of all, the QDFT and QQR decomposition are performed on the host image, respectively, to acquire the scalar part of the quaternion matrix for watermark information embedding. After that, we divide the scalar part of the quaternion matrix generated by the QQR decomposition into blocks and calculate the entropy. The block with high entropy is selected to embed the watermark information. Then the watermark information is embedded into the extracted block using the quantization index modulation method. We conducted a large number of tests and experimental results indicate that the presented approach obtains excellent robustness against Scaling, Rotation, Median filtering, `Salt \& Pepper' noise, and JPEG Compression. Compared with the existing methods, the presented method achieves better performance.},
	journal = {IEEE Access},
	author = {Li, Mianjie and Yuan, Xiaochen and Chen, Hai and Li, Jianqing},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Watermarking, Transforms, Color, Data mining, Entropy, Matrix decomposition, quantization index modulation, quaternion discrete Fourier transform (QDFT), quaternion QR (QQR) decomposition, Quaternions, scalar part, Watermarking technology},
	pages = {72308--72315},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/NWIMC37Y/9066976.html:text/html;Li et al_2020_Quaternion Discrete Fourier Transform-Based Color Image Watermarking Method.pdf:/Users/maodou/Zotero/storage/Z2XZX5EW/Li et al_2020_Quaternion Discrete Fourier Transform-Based Color Image Watermarking Method.pdf:application/pdf},
}

@article{li_adaptive_2020,
	title = {Adaptive segmentation-based feature extraction and {S}-{STDM} watermarking method for color image},
	volume = {32},
	number = {13},
	journal = {Neural Computing and Applications},
	author = {Li, Mianjie and Yuan, Xiaochen},
	year = {2020},
	note = {ISBN: 1433-3058
Publisher: Springer},
	pages = {9181--9200},
}

@article{yuan_spatial_2020,
	title = {Spatial {Domain}-{Based} {Nonlinear} {Residual} {Feature} {Extraction} for {Identification} of {Image} {Operations}},
	volume = {10},
	number = {16},
	journal = {Applied Sciences},
	author = {Yuan, Xiaochen and Huang, Tian},
	year = {2020},
	note = {ISBN: 2076-3417
Publisher: MDPI},
	pages = {5582},
}

@article{YUAN2021116038,
	title = {Gauss–{Jordan} elimination-based image tampering detection and self-recovery},
	volume = {90},
	issn = {0923-5965},
	url = {https://www.sciencedirect.com/science/article/pii/S0923596520301855},
	doi = {https://doi.org/10.1016/j.image.2020.116038},
	abstract = {This paper proposes a novel Gauss–Jordan elimination-based image tampering detection and self-recovery scheme, aiming at dealing with the problem of malicious tampering on digital images. To deal with the copy–move tampering which is challenging because the tampered region may contain the watermark information, we propose the Improved Check Bits Generation algorithm during watermark generation, to generate the check bits for tampering detection. Meanwhile, the recovery bits are reconstructed according to the fundamental of Gauss–Jordan Elimination, for purpose of image contents self-recovery. To improve the accuracy of detection and the quality of recovered images, we propose the Morphological Processing-Based Enhancement method and the Edge Extension preprocessing respectively during and after the tampering detection Finally, the Gauss–JordanElimination-Based Self-Recovery method is proposed to recover the damaged content mathematically on basis of the detected results. By employing the unchanged recovery bits which are embedded in the non-tampered region, the failure in recovery caused by the damaged recovery bits can be completely avoided. A large number of experiments have been conducted to show the very good performance of the proposed scheme. The precision, recall, and F1 score are calculated for evaluation of tampering detection, while the PSNR values are calculated for evaluation of image recovery. The comparisons with the state-of-the-art methods show that the proposed scheme shows the superiorities in terms of imperceptibility, security and recovery capability. The experimental result indicates the average PSNR of recovered image is 44.415dB.},
	journal = {Signal Processing: Image Communication},
	author = {Yuan, Xiaochen and Li, Xinhang and Liu, Tong},
	year = {2021},
	keywords = {Gauss–Jordan Elimination-Based Self-Recovery, Image tampering detection, Improved check bits generation, Morphological processing-based enhancement},
	pages = {116038},
}

@article{liu_adaptive_2021,
	title = {Adaptive {Feature} {Calculation} and {Diagonal} {Mapping} for {Successive} {Recovery} of {Tampered} {Regions}},
	volume = {31},
	issn = {1558-2205},
	doi = {10.1109/TCSVT.2020.3032455},
	abstract = {This article proposes an adaptive scheme for image tampered region localization and content recovery. To generate the watermark information comprised of the authentication data and recovery data, we firstly propose the Adaptive Authentication Feature Calculation algorithm to obtain the authentication data, which includes the information of block location and block feature. The DWT-based Block Feature Calculation method is then proposed to calculate the block feature, and the quantization method is employed to calculate the block location. The recovery data is composed of self-recovery bits and mapped-recovery bits. The self-recovery bits are obtained by the Set Partitioning in Hierarchical Trees encoding algorithm. For retrieving the damaged codes caused by tampering, we propose the Diagonal Mapping algorithm and apply it to the self-recovery bits, thus generating the mapped-recovery bits, to provide a guarantee of recovery data. Experimental results show the superior performance of the proposed scheme in terms of tamper detection and image recovery, by comparing with the state-of-the-art works. The results demonstrate that the proposed method shows efficiency in the adaptiveness, well localization, strong capability for image recovery, and the effectiveness of attack resistance.},
	number = {7},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {Liu, Tong and Yuan, Xiaochen},
	month = jul,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Circuits and Systems for Video Technology},
	keywords = {Image coding, Watermarking, Authentication, Partitioning algorithms, Adaptive authentication feature calculation, diagonal mapping, Discrete wavelet transforms, DWT-based block feature calculation, Media, successive content self-recovery, tamper detection},
	pages = {2617--2630},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/B6G3PZ4X/9233407.html:text/html;Liu_Yuan_2021_Adaptive Feature Calculation and Diagonal Mapping for Successive Recovery of.pdf:/Users/maodou/Zotero/storage/8K3335T4/Liu_Yuan_2021_Adaptive Feature Calculation and Diagonal Mapping for Successive Recovery of.pdf:application/pdf},
}

@article{liu_dual-tamper-detection_2021,
	title = {A dual-tamper-detection method for digital image authentication and content self-recovery},
	volume = {80},
	number = {19},
	journal = {Multimedia Tools and Applications},
	author = {Liu, Tong and Yuan, Xiaochen},
	year = {2021},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {29805--29826},
}

@article{li_fd-tr_2021,
	title = {{FD}-{TR}: feature detector based on scale invariant feature transform and bidirectional feature regionalization for digital image watermarking},
	volume = {80},
	number = {21},
	journal = {Multimedia Tools and Applications},
	author = {Li, Mianjie and Yuan, Xiaochen},
	year = {2021},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {32197--32217},
}

@article{FANG2022295,
	title = {Detection of weak electromagnetic interference attacks based on fingerprint in {IIoT} systems},
	volume = {126},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X21003289},
	doi = {https://doi.org/10.1016/j.future.2021.08.020},
	abstract = {In Industrial Internet of Things (IIoT) systems, the intelligent devices are vulnerable to be attacked by weak Electromagnetic Interference (EMI), thereby threatening the security of the systems. Therefore, it is of great significance to investigate the weak EMI attack of IIoT systems. The different manufacturing processes and deployment environments make the intelligent devices carry different noises, called fingerprints, which are unchanged unless these intelligent devices are attacked. Hence, we can detect weak EMI attacks by judging whether the fingerprint of intelligent device has been changed, which is different from using professional detection equipment as in other methods. Based on the fingerprint of intelligent device, this paper proposes a highly efficient weak EMI attack detection method which is divided into three steps. First, the fingerprint is extracted by Linear Time-Invariant (LTI) model and Kalman algorithm. Second, according to the extracted fingerprint, a fusion model is designed to determine whether the device is attacked by weak EMI. In the fusion model, Feature Extraction Unit (FEU) combines with Long Short-Term Memory (LSTM) to improve the detection accuracy. Finally, an edge computing framework is proposed to enhance the efficiency of the method. The experimental results show that the detection accuracy and the efficiency of the proposed method are 5.2\% and 42.2\% higher than those of the state-of-the-art method, respectively.},
	journal = {Future Generation Computer Systems},
	author = {Fang, Kai and Wang, Tingting and Yuan, Xiaochen and Miao, Chunyu and Pan, Yuanyuan and Li, Jianqing},
	year = {2022},
	keywords = {Edge computing, EMI attack, FEU-LSTM, Fingerprint, IIoT},
	pages = {295--304},
}

@article{wang_reinforcement_2022,
	title = {Reinforcement {Learning}-{Based} {Optimization} for {Mobile} {Edge} {Computing} {Scheduling} {Game}},
	issn = {2471-285X},
	doi = {10.1109/TETCI.2022.3145694},
	abstract = {Task scheduling on edge computing servers is a critical concern affecting user experience. Current scheduling methods attain an overall appealing performance through centralized control. Nevertheless, forcing users to act based on a centralized control is impractical. Hence, this work suggests a game theory-based distributed edge computing server task scheduling model. The proposed method comprehensively considers the mobile device-server link quality and the server’s computing resource allocation and balances link quality and computing resources requirements when selecting edge computing servers. Furthermore, we develop a time series prediction algorithm based on IndRNN and LSTM to accurately predict link quality. Once Nash equilibrium is reached quickly through our proposed acceleration scheme, the proposed model provides various QoS for different priority users. The experimental results highlight that the developed solution provides differentiated services while optimizing computing resource scheduling and ensuring an approximate Nash equilibrium in polynomial time.},
	journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
	author = {Wang, Tingting and Lu, Bingxian and Wang, Wei and Wei, Wei and Yuan, Xiaochen and Li, Jianqing},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Emerging Topics in Computational Intelligence},
	keywords = {Task analysis, Computational modeling, 5G mobile communication, Delays, edge computing, game theory, Games, Mobile Computing, Processor scheduling, scheduling, Servers},
	pages = {1--10},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/C53M3VBM/9704867.html:text/html;Wang et al_2022_Reinforcement Learning-Based Optimization for Mobile Edge Computing Scheduling.pdf:/Users/maodou/Zotero/storage/69UR33GI/Wang et al_2022_Reinforcement Learning-Based Optimization for Mobile Edge Computing Scheduling.pdf:application/pdf},
}

@article{li_alteration_2021,
	title = {Alteration {Detection} of {Multispectral}/{Hyperspectral} {Images} {Using} {Dual}-{Path} {Partial} {Recurrent} {Networks}},
	volume = {13},
	number = {23},
	journal = {Remote Sensing},
	author = {Li, Jinlong and Yuan, Xiaochen and Feng, Li},
	year = {2021},
	note = {ISBN: 2072-4292
Publisher: MDPI},
	pages = {4802},
}

@article{chen_rs-chain_2022,
	title = {{RS}-chain: a decentralized reputation-sharing framework for group-buying industry via hybrid blockchain},
	journal = {Cluster Computing},
	author = {Chen, Yungui and Feng, Li and Liang, Hong and Yao, Shumin and Tian, Liwei and Yuan, Xiaochen},
	year = {2022},
	note = {ISBN: 1573-7543
Publisher: Springer},
	pages = {1--16},
}

@article{zhang_blind_2022,
	title = {Blind {Dual} {Watermarking} {Scheme} {Using} {Stucki} {Kernel} and {SPIHT} for {Image} {Self}-{Recovery}},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3204865},
	abstract = {In this paper we propose a blind dual watermarking scheme using Set Partitioning in Hierarchical Trees (SPIHT) and Stucki Kernel halftone technique for the tamper detection and image self-recovery. The watermark consists of authentication bits for tampering area location and recovery bits for image restoration. We generate two recovery bits to ensure the high-quality recovery of the tampered image. The primary recovery bit is generated by the SPIHT encoding, and the secondary recovery bit is generated by the Stucki Kernel halftone technique. Then the authentication bit is generated based on the recovery bits. Before embedding the watermark, we shuffle the watermark bits through Arnold cat mapping and diagonal mapping to improve the security and quality of the restored image. LSB-based watermarking technique is used to embed the watermark into the original image to ensure the invisibility of the watermarked image. Experiments have been conducted on two datasets, BOW2 and USC-SIPI, and results show that the proposed scheme can achieve high restoration quality. Comparison with the existing works demonstrate the good performance and superiority of the proposed scheme.},
	journal = {IEEE Access},
	author = {Zhang, Qiyuan and Yuan, Xiaochen and Liu, Tong},
	year = {2022},
	note = {Conference Name: IEEE Access},
	keywords = {Kernel, Image coding, Watermarking, Authentication, Discrete wavelet transforms, Arnold cat map, authentication bit, Discrete cosine transforms, Image restoration, image self-recovery, Set partitioning in hierarchical trees (SPIHT), Stucki Kernel halftone technique},
	pages = {96100--96111},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/3TZK5Z3V/9878311.html:text/html;Zhang et al_2022_Blind Dual Watermarking Scheme Using Stucki Kernel and SPIHT for Image.pdf:/Users/maodou/Zotero/storage/76I36GZK/Zhang et al_2022_Blind Dual Watermarking Scheme Using Stucki Kernel and SPIHT for Image.pdf:application/pdf},
}

@article{li_cd-sdn_2022,
	title = {{CD}-{SDN}: {Unsupervised} {Sensitivity} {Disparity} {Networks} for {Hyper}-{Spectral} {Image} {Change} {Detection}},
	volume = {14},
	number = {19},
	journal = {Remote Sensing},
	author = {Li, Jinlong and Yuan, Xiaochen and Li, Jinfeng and Huang, Guoheng and Li, Ping and Feng, Li},
	year = {2022},
	note = {ISBN: 2072-4292
Publisher: MDPI},
	pages = {4806},
}

@article{sun_reversible_2022,
	title = {Reversible multi-watermarking for color images with grayscale invariance},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-022-14125-y},
	doi = {10.1007/s11042-022-14125-y},
	abstract = {As a special way of hiding information, reversible data hiding is mostly used to embed data into digital multimedia. The original multimedia and embedded data can be restored from the watermarked one without any loss. Being different from the traditional reversible data hiding methods, the gray scale-invariant reversible watermarking method, which keeps the grayscale of image unchanged as the information is embedded, is proposed for color images recently. Although color images are widely used in practice, there are more reversible data hiding algorithms and feature points extraction algorithms for gray images rather than color images. In this paper, two multiple watermarking mechanisms have been proposed for color images with grayscale invariance, the multi-level watermarking mechanism, where one feature region is selected and the watermarks are embedded for multiple times, and the multi-region watermarking mechanism, where the multiple non-overlapping feature regions are selected to embed watermarks. Different from others, the former mechanism uses multiple embeddings based on the feature regions to increase the embedding capacity and the latter one uses local embedding instead of global embedding to reduce the impact on the whole image. At the same time, the selection of feature points can meet certain conditions and get more suitable regions for information embedding. Experimental results show that the proposed scheme can extend the capacity efficiently while keep the characteristic of grayscale invariance.},
	journal = {Multimedia Tools and Applications},
	author = {Sun, Ying and Yuan, Xiaochen and Wang, Xingrun and Li, Jianqing},
	month = nov,
	year = {2022},
}

@article{wang_parallel_2022,
	title = {Parallel {Multiple} {Watermarking} {Using} {Adaptive} {Inter}-{Block} {Correlation}},
	journal = {Expert Systems with Applications},
	author = {Wang, Xingrun and Yuan, Xiaochen and Li, Mianjie and Sun, Ying and Tian, Jinyu and Guo, Hongfei and Li, Jianqing},
	year = {2022},
	note = {ISBN: 0957-4174
Publisher: Elsevier},
	pages = {119011},
}

@article{zhang_collaborative_2022,
	title = {Collaborative multi-feature extraction and scale-aware semantic information mining for medical image segmentation},
	volume = {67},
	issn = {0031-9155, 1361-6560},
	url = {https://iopscience.iop.org/article/10.1088/1361-6560/ac95f5},
	doi = {10.1088/1361-6560/ac95f5},
	abstract = {Objective. In recent years, methods based on U-shaped structure and skip connection have achieved remarkable results in many medical semantic segmentation tasks. However, the information integration capability of this structure is still limited due to the incompatibility of feature maps of encoding and decoding stages at corresponding levels and lack of extraction of valid information in the ﬁnal stage of encoding. This structural defect is particularly obvious in segmentation tasks with non-obvious, small and blurred-edge targets. Our objective is to design a novel segmentation network to solve the above problems. Approach. The segmentation network named Global Context-Aware Network is mainly designed by inserting a Multi-feature Collaboration Adaptation (MCA) module, a Scale-Aware Mining (SAM) module and an Edge-enhanced Pixel Intensity Mapping (Edge-PIM) into the U-shaped structure. Firstly, the MCA module can integrate information from all encoding stages and then effectively acts on the decoding stages, solving the problem of information loss during downsampling and pooling. Secondly, the SAM module can further mine information from the encoded high-level features to enrich the information passed to the decoding stage. Thirdly, EdgePIM can further reﬁne the segmentation results by edge enhancement. Main results. We newly collect Magnetic Resonance Imaging of Colorectal Cancer Liver Metastases (MRI-CRLM) dataset in different imaging sequences with non-obvious, small and blurred-edge liver metastases. Our method performs well on the MRI-CRLM dataset and the publicly available ISIC-2018 dataset, outperforming state-ofthe-art methods such as CPFNet on multiple metrics after boxplot analysis, indicating that it can perform well on a wide range of medical image segmentation tasks. Signiﬁcance. The proposed method solves the problem mentioned above and improved segmentation accuracy for non-obvious, small and blurred-edge targets. Meanwhile, the proposed visualization method Edge-PIM can make the edge more prominent, which can assist medical radiologists in their research work well.},
	language = {en},
	number = {20},
	urldate = {2022-11-02},
	journal = {Physics in Medicine \& Biology},
	author = {Zhang, Ruijun and He, Zixuan and Zhu, Jian and Yuan, Xiaochen and Huang, Guoheng and Pun, Chi-Man and Peng, Jianhong and Lin, Junzhong and Zhou, Jian},
	month = oct,
	year = {2022},
	pages = {205008},
	file = {Zhang 等 - 2022 - Collaborative multi-feature extraction and scale-a.pdf:/Users/maodou/Zotero/storage/WWKZTYZI/Zhang 等 - 2022 - Collaborative multi-feature extraction and scale-a.pdf:application/pdf},
}

@inproceedings{yuan_invariant_2012,
	title = {Invariant {Image} {Watermarking} {Using} {Harris} {Feature} {Extraction} and {Zernike} {Moments}},
	booktitle = {{ISA} 2012},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	year = {2012},
}

@article{pun_geometric_2010,
	title = {Geometric {Invariant} {Digital} {Image} {Watermarking} {Scheme} {Based} on {Histogram} in {DWT} {Domain}},
	volume = {5},
	doi = {10.4304/jmm.5.5.434-442},
	abstract = {A robust and geometric invariant digital watermarking scheme for gray-level images is proposed in this paper. The scheme carries out watermark embedding and extraction based on histogram in DWT domain. For watermark embedding, firstly, the original image is decomposed into the approximation and details sub-bands, of which, the approximation sub-band is used for watermark embedding. Pixels of the approximation subband are grouped into m blocks, each of which has the same number of gray-levels, thus the block histogram is generated; with the block histogram, the percentage of number of pixels in each block is calculated. Then some pixels in a block are moved to form a specific pattern in the gray-level histogram distribution, indicating the watermark. Finally, the embedded approximation sub-band and the other three details sub-bands are constructed into a watermarked image. For watermark extraction, firstly, the watermarked image is also decomposed into the approximation and details sub-bands; then the pixels in the approximation sub-band are grouped into blocks in the similar manner. According to the histogram distribution in each block, the watermark is extracted. Experimental results show that the proposed scheme is highly robust against JPEG compression, geometric attacks and some common signal processing, and it outperforms the existing methods in term of robustness.},
	journal = {Journal of Multimedia},
	author = {Pun, Chi-Man and Yuan, Xiaochen},
	month = oct,
	year = {2010},
	pages = {434--442},
}

@article{yuan_geometrically_2012,
	title = {Geometrically invariant image watermarking based on feature extraction and {Zernike} transform},
	volume = {6},
	number = {2},
	journal = {International Journal of Security and its Applications},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	year = {2012},
	note = {ISBN: 1738-9976},
	pages = {217--222},
}

@article{YUAN20132087,
	title = {Geometric invariant watermarking by local {Zernike} moments of binary image patches},
	volume = {93},
	issn = {0165-1684},
	url = {https://www.sciencedirect.com/science/article/pii/S0165168413000418},
	doi = {https://doi.org/10.1016/j.sigpro.2013.01.024},
	abstract = {A novel digital image watermarking scheme based on feature extraction and local Zernike transform is proposed in this paper. We proposed a local Zernike moments based watermarking scheme where the watermarked image/region can be obtained directly by inverse Zernike Transform. An edge-based feature detector is proposed for local region extraction, with which, the distinct circular patch of given size can be extracted for watermark embedding and extraction. The extracted circular patch is decomposed into a collection of binary patches and Zernike transform is applied to the selected binary patches. Magnitudes of the local Zernike moments are calculated and modified to embed the watermarks. Experimental results show that the proposed watermarking scheme is very robust against geometric distortion such as rotation, scaling, cropping, and affine transformation; and common signal processing such as JPEG compression, median filtering, and low-pass Gaussian filtering.},
	number = {7},
	journal = {Signal Processing},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man and Chen, C.-L. Philip},
	year = {2013},
	keywords = {Feature extraction, Edge-based feature detector, Inverse Zernike transform, Local Zernike transform},
	pages = {2087--2095},
}

@article{pun_robust_2013,
	title = {Robust {Segments} {Detector} for {De}-{Synchronization} {Resilient} {Audio} {Watermarking}},
	volume = {21},
	issn = {1558-7924},
	doi = {10.1109/TASL.2013.2279312},
	abstract = {A robust feature points detector for invariant audio watermarking is proposed in this paper. The audio segments centering at the detected feature points are extracted for both watermark embedding and extraction. These feature points are invariant to various attacks and will not be changed much for maintaining high auditory quality. Besides, high robustness and inaudibility can be achieved by embedding the watermark into the approximation coefficients of Stationary Wavelet Transform (SWT) domain, which is shift invariant. The spread spectrum communication technique is adopted to embed the watermark. Experimental results show that the proposed Robust Audio Segments Extractor (RASE) and the watermarking scheme are not only robust against common audio signal processing, such as low-pass filtering, MP3 compression, echo addition, volume change, and normalization; and distortions introduced in Stir-mark benchmark for Audio; but also robust against synchronization geometric distortions simultaneously, such as resample time-scale modification (TSM) with scaling factors up to ±50\%, pitch invariant TSM by ±50\%, and tempo invariant pitch shifting by ±50\%. In general, the proposed scheme can well resist various attacks by the joint RASE and SWT approach, which performs much better comparing with the existing state-of-the art methods.},
	number = {11},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Pun, Chi-Man and Yuan, Xiao-Chen},
	month = nov,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Audio, Speech, and Language Processing},
	keywords = {Feature extraction, Robustness, Watermarking, Synchronization, Distortion, Digital audio players, pitch shifting, Robust audio segments extractor (RASE), stationary wavelet transform (SWT), synchronization geometric distortions, time-scale modification (TSM)},
	pages = {2412--2424},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/6A9FDNPW/6583994.html:text/html;Pun_Yuan_2013_Robust Segments Detector for De-Synchronization Resilient Audio Watermarking.pdf:/Users/maodou/Zotero/storage/42RGCKTQ/Pun_Yuan_2013_Robust Segments Detector for De-Synchronization Resilient Audio Watermarking.pdf:application/pdf},
}

@article{pun_histogram_2015,
	title = {Histogram modification based image watermarking resistant to geometric distortions},
	volume = {74},
	number = {18},
	journal = {Multimedia Tools and Applications},
	author = {Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2015},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {7821--7842},
}

@article{yuan_feature_2014,
	title = {Feature extraction and local {Zernike} moments based geometric invariant watermarking},
	volume = {72},
	number = {1},
	journal = {Multimedia tools and applications},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	year = {2014},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {777--799},
}

@article{YUAN2015159,
	title = {Robust {Mel}-{Frequency} {Cepstral} coefficients feature detection and dual-tree complex wavelet transform for digital audio watermarking},
	volume = {298},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S002002551401130X},
	doi = {https://doi.org/10.1016/j.ins.2014.11.040},
	abstract = {A novel digital audio watermarking scheme based on robust Mel-Frequency Cepstral coefficients feature detection and dual-tree complex wavelet transform is proposed in this paper, which is similar as patchwork based methods that several segments are extracted from the host audio clip for watermarking use. The robust Mel-Frequency Cepstral coefficients feature detection method is proposed to extract the feature segments which should be relocated when the host audio signal attacked by various distortions including both the common audio signal processing and the conventional geometric distortions. With the robust feature segments, the approximate shift invariant transform dual-tree complex wavelet transform based watermarking method is proposed to embed the watermark into the DT CWT real low-pass coefficients of each segment, using the spread spectrum techniques. The linear correlation is calculated to judge the existence of the watermark during the watermark detection. Experimental results show that the proposed digital audio watermarking scheme based on robust Mel-Frequency Cepstral coefficients feature detection and dual-tree complex wavelet transform can achieve high robustness against the common audio signal processing, such as low-pass filtering, MP3 compression, echo addition, volume change, and normalization; and geometric distortions, such as resample Time-Scale Modification (TSM), pitch invariant TSM, and tempo invariant pitch shifting. In addition, the proposed audio watermarking scheme is resilient to Stir-mark for Audio, and it performs much better comparing with the existing state-of-the art methods.},
	journal = {Information Sciences},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man and Philip Chen, C.L.},
	year = {2015},
	keywords = {Dual-Tree Complex Wavelet Transform (DT CWT), Mel-Frequency Cepstral Coefficients, Pitch shifting, Stir-mark, Time-Scale Modification (TSM)},
	pages = {159--179},
}

@article{pun_image_2015,
	title = {Image {Forgery} {Detection} {Using} {Adaptive} {Oversegmentation} and {Feature} {Point} {Matching}},
	volume = {10},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2015.2423261},
	abstract = {A novel copy-move forgery detection scheme using adaptive oversegmentation and feature point matching is proposed in this paper. The proposed scheme integrates both block-based and keypoint-based forgery detection methods. First, the proposed adaptive oversegmentation algorithm segments the host image into nonoverlapping and irregular blocks adaptively. Then, the feature points are extracted from each block as block features, and the block features are matched with one another to locate the labeled feature points; this procedure can approximately indicate the suspected forgery regions. To detect the forgery regions more accurately, we propose the forgery region extraction algorithm, which replaces the feature points with small superpixels as feature blocks and then merges the neighboring blocks that have similar local color features into the feature blocks to generate the merged regions. Finally, it applies the morphological operation to the merged regions to generate the detected forgery regions. The experimental results indicate that the proposed copy-move forgery detection scheme can achieve much better detection results even under various challenging conditions compared with the existing state-of-the-art copy-move forgery detection methods.},
	number = {8},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Pun, Chi-Man and Yuan, Xiao-Chen and Bi, Xiu-Li},
	month = aug,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Forgery, Digital images, Feature extraction, Image color analysis, Image segmentation, Copy-move forgery detection, Discrete wavelet transforms, adaptive over-segmentation, Adaptive Over-Segmentation, Copy-Move Forgery Detection, forgery region extraction, Forgery Region Extraction, local color feature, Local Color Feature},
	pages = {1705--1716},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/964UJLNB/7086315.html:text/html;Pun et al_2015_Image Forgery Detection Using Adaptive Oversegmentation and Feature Point.pdf:/Users/maodou/Zotero/storage/NST8Z3HL/Pun et al_2015_Image Forgery Detection Using Adaptive Oversegmentation and Feature Point.pdf:application/pdf},
}

@article{YAN20161,
	title = {Multi-scale image hashing using adaptive local feature extraction for robust tampering detection},
	volume = {121},
	issn = {0165-1684},
	url = {https://www.sciencedirect.com/science/article/pii/S0165168415003709},
	doi = {https://doi.org/10.1016/j.sigpro.2015.10.027},
	abstract = {The main problem addressed in this paper is the robust tampering detection of the image received in a transmission under various content-preserving attacks. To this aim the multi-scale image hashing method is proposed by using the location-context information of the features generated by adaptive and local feature extraction techniques. The generated hash is attached to the image before transmission and analyzed at destination to filter out the geometric transformations occurred in the received image by image restoration firstly. Based on the restored image, the image authentication using the global and color hash component is performed to determine whether the received image has the same contents as the trusted one or has been maliciously tampered, or just different. After regarding the received image as being tampered, the tampered regions will be localized through the multi-scale hash component. Lots of experiments are conducted to indicate that our tampering detection scheme outperforms the existing state-of-the-art methods and is very robust against the content-preserving attacks, including both common signal processing and geometric distortions.},
	journal = {Signal Processing},
	author = {Yan, Cai-Ping and Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2016},
	keywords = {Adaptive Feature Point Detection, Image authentication, Multi-scale image hashing, Tampering detection},
	pages = {1--16},
}

@article{BI2016226,
	title = {Multi-level dense descriptor and hierarchical feature matching for {Copy}–{Move} forgery detection},
	volume = {345},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025516000955},
	doi = {https://doi.org/10.1016/j.ins.2016.01.061},
	abstract = {In this paper, a Multi-Level Dense Descriptor (MLDD) extraction method and a Hierarchical Feature Matching method are proposed to detect copy–move forgery in digital images. The MLDD extraction method extracts the dense feature descriptors using multiple levels, while the extracted dense descriptor consists of two parts: the Color Texture Descriptor and the Invariant Moment Descriptor. After calculating the MLDD for each pixel, the Hierarchical Feature Matching method subsequently detects forgery regions in the input image. First, the pixels that have similar color textures are grouped together into distinctive neighbor pixel sets. Next, each pixel is matched with pixels in its corresponding neighbor pixel set through its geometric invariant moments. Then, the redundant pixels from previously generated matched pixel pairs are filtered out by the proposed Adaptive Distance and Orientation Based Filtering method. Finally, some morphological operations are applied to generate the final detected forgery regions. Experimental results show that the proposed scheme can achieve much better detection results compared with the existing state-of-the-art CMFD methods, even under various challenging conditions such as geometric transforms, JPEG compression, noise addition and down-sampling.},
	journal = {Information Sciences},
	author = {Bi, Xiuli and Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2016},
	keywords = {Color Texture Descriptor, Copy–Move Forgery Detection (CMFD), Hierarchical Feature Matching, Invariant Moment Descriptor, Multi-Level Dense Descriptor (MLDD)},
	pages = {226--242},
}

@article{PUN2016195,
	title = {Multi-scale noise estimation for image splicing forgery detection},
	volume = {38},
	issn = {1047-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S1047320316300098},
	doi = {https://doi.org/10.1016/j.jvcir.2016.03.005},
	abstract = {Noise discrepancies in multiple scales are utilized as indicators for image splicing forgery detection in this paper. Specifically, the test image is initially segmented into superpixels of multiple scales. In each individual scale, noise level function, which reflects the relation between noise level and brightness of each segment, is computed. Those segments not constrained by the noise level function are regarded as suspicious regions. In the final step, pixels appears in suspicious regions of each scale, after necessary morphological processing, are marked as spliced region(s). The Optimal Parameter Combination Searching (OPCS) Algorithm is proposed to determine the optimal parameters during the process. Two datasets are created for training the optimal parameters and to evaluate the proposed scheme, respectively. The experimental results show that the proposed scheme is effective, especially for the multi-objects splicing. In addition, the proposed scheme is proven to be superior to the existing state-of-the-art method.},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Pun, Chi-Man and Liu, Bo and Yuan, Xiao-Chen},
	year = {2016},
	keywords = {Multi-scale noise estimation, Noise level function, Optimal Parameter Combination Searching (OPCS), SLIC superpixels, Splicing forgery},
	pages = {195--206},
}

@article{yan_quaternion-based_2016,
	title = {Quaternion-{Based} {Image} {Hashing} for {Adaptive} {Tampering} {Localization}},
	volume = {11},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2016.2594136},
	abstract = {Image-hashing-based tampering detection methods have been widely studied with continuous advancements. However, most of existing models are designed for a specific tampering. In this paper, we propose a novel quaternion-based image hashing to detect almost all types of tampering, including color changing, copy move, splicing, and so on. First, the quaternion Fourier-Mellin transform is used to calculate the geometric hash to eliminate the influence of geometric distortions. Then, a new quaternion image construction method, which combines advantages of both color and structural features, is proposed to implement the quaternion Fourier transform to calculate the image feature hash to locate the tampered regions. The objective is to provide a reasonably short image hashing with good performance, i.e., being perceptually robust against various content-preserving attacks while capable of detecting and locating almost all types of tampering. Furthermore, an adaptive tampering localization algorithm is proposed based on clustering analysis to improve the detection accuracy. The experimental results show that the proposed tampering detection model outperforms the existing state-of-the-art models and is very robust against various content-preserving attacks.},
	number = {12},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Yan, Cai-Ping and Pun, Chi-Man and Yuan, Xiao-Chen},
	month = dec,
	year = {2016},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Feature extraction, Image color analysis, Robustness, Splicing, Authentication, Transforms, Quaternions, adaptive tampering localization, Image hashing, quaternion Fourier transform (QFT), quaternion Fourier-Mellin transform (QMMT)},
	pages = {2664--2677},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/KB5UBD32/7523392.html:text/html;Yan et al_2016_Quaternion-Based Image Hashing for Adaptive Tampering Localization.pdf:/Users/maodou/Zotero/storage/XK4E3SH6/Yan et al_2016_Quaternion-Based Image Hashing for Adaptive Tampering Localization.pdf:application/pdf},
}

@article{pun_robust_2018,
	title = {Robust image hashing using progressive feature selection for tampering detection},
	volume = {77},
	number = {10},
	journal = {Multimedia Tools and Applications},
	author = {Pun, Chi-Man and Yan, Cai-Ping and Yuan, Xiao-Chen},
	year = {2018},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {11609--11633},
}

@article{pun_image_2017,
	title = {Image {Alignment}-{Based} {Multi}-{Region} {Matching} for {Object}-{Level} {Tampering} {Detection}},
	volume = {12},
	issn = {1556-6013, 1556-6021},
	url = {http://ieeexplore.ieee.org/document/7583645/},
	doi = {10.1109/TIFS.2016.2615272},
	abstract = {Tampering detection methods based on image hashing have been widely studied with continuous advancements. However, most existing models cannot generate object-level tampering localization results, because the forensic hashes attached to the image lack contour information. In this paper, we present a novel tampering detection model that can generate an accurate, object-level tampering localization result. First, an adaptive image segmentation method is proposed to segment the image into closed regions based on strong edges. Then, the color and position features of the closed regions are extracted as a forensic hash. Furthermore, a geometric invariant tampering localization model named image alignment-based multi-region matching (IAMRM) is proposed to establish the region correspondence between the received and forensic images by exploiting their intrinsic structure information. The model estimates the parameters of geometric transformations via a robust image alignment method based on triangle similarity; in addition, it matches multiple regions simultaneously by utilizing manifold ranking based on different graph structures and features. Experimental results demonstrate that the proposed IAMRM is a promising method for object-level tampering detection compared with the state-ofthe-art methods.},
	language = {en},
	number = {2},
	urldate = {2022-10-28},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Pun, Chi-Man and Yan, Caiping and Yuan, Xiao-Chen},
	month = feb,
	year = {2017},
	pages = {377--391},
	file = {Pun 等。 - 2017 - Image Alignment-Based Multi-Region Matching for Ob.pdf:/Users/maodou/Zotero/storage/GG3ED2K5/Pun 等。 - 2017 - Image Alignment-Based Multi-Region Matching for Ob.pdf:application/pdf},
}

@article{bi_multi-scale_2018,
	title = {Multi-scale feature extraction and adaptive matching for copy-move forgery detection},
	volume = {77},
	number = {1},
	journal = {Multimedia Tools and Applications},
	author = {Bi, XiuLi and Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2018},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {363--385},
}

@article{han_regframe_2018,
	title = {{RegFrame}: fast recognition of simple human actions on a stand-alone mobile device},
	volume = {30},
	number = {9},
	journal = {Neural Computing and Applications},
	author = {Han, Di and Li, Jianqing and Zeng, Zihua and Yuan, Xiaochen and Li, Wenting},
	year = {2018},
	note = {ISBN: 1433-3058
Publisher: Springer},
	pages = {2787--2793},
}

@article{zhao_ida-net_2023,
	title = {{IDA}-{Net}: {Inheritable} {Deformable} {Attention} {Network} of structural {MRI} for {Alzheimer}’s {Disease} {Diagnosis}},
	volume = {84},
	issn = {1746-8094},
	shorttitle = {{IDA}-{Net}},
	url = {https://www.sciencedirect.com/science/article/pii/S1746809423002203},
	doi = {10.1016/j.bspc.2023.104787},
	abstract = {To precisely diagnose neurological diseases, such as Alzheimer’s disease, clinicians need to observe the microstructural changes of local brain atrophy with the help of structural magnetic resonance image (sMRI). Some Convolutional Neural Networks (CNNs) have recently achieved excellent performance in auxiliary clinicians to provide the diagnosis suggestion. However, there still exist several challenges. Foremost, several researchers manually predefine some regions of interest (ROIs) as the input of the CNN-based networks, which impedes the model’s robustness and interpretability of clinical applications. Second, since the position relevance of pathological features interferes with the surrounding tissue regions in ROIs, it is hard for the current CNN-based networks to extract the microstructural changes of these ROIs precisely. To address the above challenges, we optimize the Transformer structure for Alzheimer’s Disease Diagnosis and propose an Inheritable Deformable Attention Network (IDA-Net). Specifically, the IDA-Net mainly comprises the 3D Deformable Self-Attention module and the Inheritable 3D Deformable Self-Attention module. The 3D Deformable Self-Attention module can automatically adjust the position and scale of the selected patches according to the structural changes in sMRI. Furthermore, the Inheritable 3D Deformable Self-Attention module can locate and output relatively important regions with discriminative features in sMRI, which can assist physicians in the clinical diagnosis. Our proposed IDA-Net method is evaluated on the sMRI of 2813 subjects from ADNI and AIBL datasets. The results show that our IDA-Net method behaves better than several state-of-the-art methods in classification performance and model generalization.},
	language = {en},
	urldate = {2023-03-21},
	journal = {Biomedical Signal Processing and Control},
	author = {Zhao, Qin and Huang, Guoheng and Xu, Pingping and Chen, Ziyang and Li, Wenyuan and Yuan, Xiaochen and Zhong, Guo and Pun, Chi-Man and Huang, Zhixin},
	month = jul,
	year = {2023},
	keywords = {Deep learning, Alzheimer’s Disease Diagnosis, Computer-aided diagnosis, Deformation, Inheritance, Self-attention, Structural magnetic resonance image, Transformer},
	pages = {104787},
	file = {ScienceDirect Snapshot:/Users/maodou/Zotero/storage/8RCSPVLK/S1746809423002203.html:text/html},
}

@article{lin_quaternion_2023,
	title = {Quaternion attention multi-scale widening network for endoscopy image super-resolution},
	issn = {0031-9155},
	url = {http://iopscience.iop.org/article/10.1088/1361-6560/acc002},
	doi = {10.1088/1361-6560/acc002},
	abstract = {Objective. In the field of endoscopic imaging, Super-Resolution (SR) plays an important role in Manufactured Diagnosis, physicians and machine Automatic Diagnosis. Although many recent studies have been performed, by using deep convolutional neural networks on endoscopic Super-Resolution, most of the methods have large parameters, which limits their practical application. In addition, almost all of these methods treat each channel equally based on the real-valued domain, without considering the difference among the different channels. Our objective is to design a super-resolution model named Quaternion Attention Multi-scale Widening Network (QAMWN) for endoscopy images to address the above problem. Approach. QAMWN contains a stacked Quaternion Attention Multi-Scale Widening Block (QAMWB), that composed of Multi-Scale Feature Widening Aggregation Module (MFWAM) and Quaternion Residual Channel Attention (QRCA). The MFWAM adopts multi-scale architecture with step-wise widening on feature channels for better feature extraction; and in QRCA, quaternion is introduced to construct Residual Channel Attention Mechanism, which obtains adaptively scales features by considering compact cross channel interactions in the hyper-complex domain. Main results. To verify the efficacy of our method, it is performed on two public endoscopic datasets, CVC ClinicDB and Kvasir dataset. The experimental results show that our proposed method can achieve a better trade-off in model size and performance. More importantly, the proposed QAMWN outperforms previous state-of-the-art methods in both metrics and visualization. Significance. We propose a lightweight super-resolution network for endoscopy and achieves better performance with fewer parameters, which helps in clinical diagnosis of endoscopy.},
	language = {en},
	urldate = {2023-03-21},
	journal = {Physics in Medicine \& Biology},
	author = {Lin, Junyu and Huang, Guoheng and Huang, Jun and Yuan, Xiaochen and Zeng, Yiwen and Shi, Cheng},
	year = {2023},
}

@article{bao_point_2023,
	title = {Point {Cloud} {Plane} {Segmentation}-{Based} {Robust} {Image} {Matching} for {Camera} {Pose} {Estimation}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/15/2/497},
	doi = {10.3390/rs15020497},
	abstract = {The mainstream image matching method for recovering the motion of the camera is based on local feature matching, which faces the challenges of rotation, illumination, and the presence of dynamic objects. In addition, local feature matching relies on the distance between descriptors, which easily leads to lots of mismatches. In this paper, we propose a new robust image matching method for camera pose estimation, called IM\_CPE. It is a novel descriptor matching method combined with 3-D point clouds for image matching. Specifically, we propose to extract feature points based on a pair of matched point cloud planes, which are generated and segmented based on depth images. Then, the feature points are matched based on the distance between their corresponding 3-D points on the point cloud planes and the distance between their descriptors. Moreover, the robustness of the matching can be guaranteed by the centroid distance of the matched point cloud planes. We evaluate the performance of IM\_CPE using four well-known key point extraction algorithms, namely Scale-Invariant Feature Transform (SIFT), Speed Up Robust Feature (SURF), Features from Accelerated Segment Test (FAST), and Oriented FAST and Rotated Brief (ORB), with four sequences from the TUM RGBD dataset. According to the experimental results, compared to the original SIFT, SURF, FAST, and ORB algorithms, the NN\_mAP performance of the four key point algorithms has been improved by 11.25\%, 13.98\%, 16.63\%, and 10.53\% on average, respectively, and the M.Score has also been improved by 25.15\%, 23.05\%, 22.28\%, and 11.05\% on average, respectively. The results show that the IM\_CPE can be combined with the existing key points extraction algorithms and the IM\_CPE can significantly improve the performance of these key points algorithms.},
	language = {en},
	number = {2},
	urldate = {2023-03-21},
	journal = {Remote Sensing},
	author = {Bao, Junqi and Yuan, Xiaochen and Huang, Guoheng and Lam, Chan-Tong},
	month = jan,
	year = {2023},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {camera pose estimation, image matching, image segmentation, key points extraction, point cloud},
	pages = {497},
	file = {Full Text PDF:/Users/maodou/Zotero/storage/446U6UJ8/Bao 等 - 2023 - Point Cloud Plane Segmentation-Based Robust Image .pdf:application/pdf},
}

@article{han_weakly_2023,
	title = {Weakly supervised semantic segmentation of histological tissue via attention accumulation and pixel-level contrast learning},
	volume = {68},
	issn = {0031-9155},
	url = {https://dx.doi.org/10.1088/1361-6560/acaeee},
	doi = {10.1088/1361-6560/acaeee},
	abstract = {Objective. Histopathology image segmentation can assist medical professionals in identifying and diagnosing diseased tissue more efficiently. Although fully supervised segmentation models have excellent performance, the annotation cost is extremely expensive. Weakly supervised models are widely used in medical image segmentation due to their low annotation cost. Nevertheless, these weakly supervised models have difficulty in accurately locating the boundaries between different classes of regions in pathological images, resulting in a high rate of false alarms Our objective is to design a weakly supervised segmentation model to resolve the above problems. Approach. The segmentation model is divided into two main stages, the generation of pseudo labels based on class residual attention accumulation network (CRAANet) and the semantic segmentation based on pixel feature space construction network (PFSCNet). CRAANet provides attention scores for each class through the class residual attention module, while the Attention Accumulation (AA) module overlays the attention feature maps generated in each training epoch. PFSCNet employs a network model containing an inflated convolutional residual neural network and a multi-scale feature-aware module as the segmentation backbone, and proposes dense energy loss and pixel clustering modules are based on contrast learning to solve the pseudo-labeling-inaccuracy problem. Main results. We validate our method using the lung adenocarcinoma (LUAD-HistoSeg) dataset and the breast cancer (BCSS) dataset. The results of the experiments show that our proposed method outperforms other state-of-the-art methods on both datasets in several metrics. This suggests that it is capable of performing well in a wide variety of histopathological image segmentation tasks. Significance. We propose a weakly supervised semantic segmentation network that achieves approximate fully supervised segmentation performance even in the case of incomplete labels. The proposed AA and pixel-level contrast learning also make the edges more accurate and can well assist pathologists in their research.},
	language = {en},
	number = {4},
	urldate = {2023-03-21},
	journal = {Physics in Medicine \& Biology},
	author = {Han, Yongqi and Cheng, Lianglun and Huang, Guoheng and Zhong, Guo and Li, Jiahua and Yuan, Xiaochen and Liu, Hongrui and Li, Jiao and Zhou, Jian and Cai, Muyan},
	month = feb,
	year = {2023},
	note = {Publisher: IOP Publishing},
	pages = {045010},
}

@article{zhang_c3mw_2023,
	title = {{C3MW}: {A} {Novel} {Comprehensive}-{Monitoring}-{Motivated} {Multi}-model {Watermarking} {Scheme} for {Tamper} {Detection} and {Self}-recovery},
	issn = {13191578},
	shorttitle = {{C3MW}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S131915782300349X},
	doi = {10.1016/j.jksuci.2023.101795},
	abstract = {In this paper, we propose a novel Comprehensive-Monitoring-Motivated Multi-model Watermarking (C3MW) Scheme for tampering region localization and self-recovery for 4K images. To generate the Comprehensive-Monitoring-Motivated Multi-model (C3M) Watermark, the MultiModel Authentication Bits Generation (MMAG) method and the Adaptive Block SignificanceBased Recovery Bits Generation (ASRG) method, are proposed. The MMAG aims to monitor the various bit-plane information for detecting the possible tampering in a more comprehensive manner. When performing image tampering detection, once one of the multiple models is triggered, the corresponding parcel will be marked as tampered. On basis of the detected regions, we propose a fine-tuning-based image recovery method, where the extracted recovery data consist of the fused Adaptive Block Significance (ABS) and bitmaps, while the calculated recovery data consist of the watermark information which is calculated from the received image. We conduct experiments on two public databases, respectively, the BOWS2 Dataset and the LIU4K-v2 Dataset. Comparisons with existing state-of-the-art works have been performed on the BOWS2 dataset, and our scheme improves the precision and F1 Score by 7.27\% and 3.30\%, respectively. It is clear from these results that our method has a better performance than others.},
	language = {en},
	urldate = {2023-10-18},
	journal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Zhang, Qiyuan and Yuan, Xiaochen and Lam, Chan-Tong and Xing, Zheng and Huang, Guoheng},
	month = oct,
	year = {2023},
	pages = {101795},
	file = {Zhang 等 - 2023 - C3MW A Novel Comprehensive-Monitoring-Motivated M.pdf:/Users/maodou/Zotero/storage/CVIK7TU9/Zhang 等 - 2023 - C3MW A Novel Comprehensive-Monitoring-Motivated M.pdf:application/pdf},
}

@article{chen_quaternion_2023,
	title = {Quaternion {Cross}-modality {Spatial} {Learning} for {Multi}-modal {Medical} {Image} {Segmentation}},
	issn = {2168-2194, 2168-2208},
	url = {https://ieeexplore.ieee.org/document/10373023/},
	doi = {10.1109/JBHI.2023.3346529},
	abstract = {Recently, the Deep Neural Networks (DNNs) have had a large impact on imaging process including medical image segmentation, and the real-valued convolution of DNN has been extensively utilized in multi-modal medical image segmentation to accurately segment lesions via learning data information. However, the weighted summation operation in such convolution limits the ability to maintain spatial dependence that is crucial for identifying different lesion distributions. In this paper, we propose a novel Quaternion Cross-modality Spatial Learning (Q-CSL) which explores the spatial information while considering the linkage between multi-modal images. Specifically, we introduce to quaternion to represent data and coordinates that contain spatial information. Additionally, we propose Quaternion Spatial-association Convolution to learn the spatial information. Subsequently, the proposed De-level Quaternion Cross-modality Fusion (De-QCF) module excavates inner space features and fuses cross-modality spatial dependency. Our experimental results demonstrate that our approach compared to the competitive methods perform well with only 0.01061M parameters and 9.95G FLOPs. Our code is available at https://github.com/cjyang123456/QCSL.git.},
	language = {en},
	urldate = {2024-01-12},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Chen, Junyang and Huang, Guoheng and Yuan, Xiaochen and Zhong, Guo and Zheng, Zewen and Pun, Chi-Man and Zhu, Jian and Huang, Zhixin},
	year = {2023},
	pages = {1--12},
	file = {Chen 等 - 2023 - Quaternion Cross-modality Spatial Learning for Mul.pdf:/Users/maodou/Zotero/storage/LZJB9B8J/Chen 等 - 2023 - Quaternion Cross-modality Spatial Learning for Mul.pdf:application/pdf},
}

@article{he_progressive_2024,
	title = {Progressive normalizing flow with learnable spectrum transform for style transfer},
	volume = {284},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705123010250},
	doi = {10.1016/j.knosys.2023.111277},
	abstract = {Most current style transfer models are designed as encoder–decoder structures. Some encoding operations, such as downsampling and pooling, cause a loss of image details. If the encoder and decoder are not compatible, it can also introduce distortion. Reversible neural networks have demonstrated their superior power in lossless projection. However, since the inputs and outputs of neural flows are holistic features, merely the high-level features can be utilized for image generation through reverse inference. These high-level features emphasize the image style more, leading to the generated results easily losing content details and producing abstract colors. To address the above issues, we propose LSTFlow, the first progressive reversible neural network capable of feature decomposition. First, LSTFlow incorporates our proposed reversible Learnable Spectrum Transform (LST), which can dynamically decompose the feature into feature spectrum and recover them losslessly. LSTFlow can retain more details by enabling multi-level features to be fused in backward inference. Second, we propose a Progressive Flow Stylization Strategy (PFSS) to balance the model’s emphasis between content and style and enhance the color perception. Forward inference based PFSS is carried out progressively, while the backward inference focuses on progressive generation. To demonstrate the effectiveness of our proposed method, we conducted comparative experiments with seven other state-of-the-art algorithms. The stylized effects are evaluated in terms of visual effects and quantitative indicators. The experiments show that the lightest LSTFlow performs the best in SSIM, Color Entropy, Color Uniformity and FID indicators and outperforms state-of-the-art methods.},
	language = {en},
	urldate = {2024-01-12},
	journal = {Knowledge-Based Systems},
	author = {He, Zixuan and Huang, Guoheng and Yuan, Xiaochen and Zhong, Guo and Pun, Chi-Man and Zeng, Yiwen},
	month = jan,
	year = {2024},
	pages = {111277},
	file = {He 等 - 2024 - Progressive normalizing flow with learnable spectr.pdf:/Users/maodou/Zotero/storage/TMYQ28TK/He 等 - 2024 - Progressive normalizing flow with learnable spectr.pdf:application/pdf},
}

@article{yuan_triangular_2024,
	title = {Triangular {Chain} {Closed}-{Loop} {Detection} {Network} for {Dense} {Pedestrian} {Detection}},
	volume = {73},
	issn = {0018-9456, 1557-9662},
	url = {https://ieeexplore.ieee.org/document/10352356/},
	doi = {10.1109/TIM.2023.3341131},
	language = {en},
	urldate = {2024-01-12},
	journal = {IEEE Transactions on Instrumentation and Measurement},
	author = {Yuan, Qishen and Huang, Guoheng and Zhong, Guo and Yuan, Xiaochen and Tan, Zhe and Lu, Zeng and Pun, Chi-Man},
	year = {2024},
	pages = {1--14},
	file = {Yuan 等 - 2024 - Triangular Chain Closed-Loop Detection Network for.pdf:/Users/maodou/Zotero/storage/DC64NYRS/Yuan 等 - 2024 - Triangular Chain Closed-Loop Detection Network for.pdf:application/pdf},
}

@article{deng_qmls_2023,
	title = {{QMLS}: quaternion mutual learning strategy for multi-modal brain tumor segmentation},
	volume = {69},
	issn = {0031-9155},
	shorttitle = {{QMLS}},
	url = {https://dx.doi.org/10.1088/1361-6560/ad135e},
	doi = {10.1088/1361-6560/ad135e},
	abstract = {Objective. Due to non-invasive imaging and the multimodality of magnetic resonance imaging (MRI) images, MRI-based multi-modal brain tumor segmentation (MBTS) studies have attracted more and more attention in recent years. With the great success of convolutional neural networks in various computer vision tasks, lots of MBTS models have been proposed to address the technical challenges of MBTS. However, the problem of limited data collection usually exists in MBTS tasks, making existing studies typically have difficulty in fully exploring the multi-modal MRI images to mine complementary information among different modalities. Approach. We propose a novel quaternion mutual learning strategy (QMLS), which consists of a voxel-wise lesion knowledge mutual learning mechanism (VLKML mechanism) and a quaternion multi-modal feature learning module (QMFL module). Specifically, the VLKML mechanism allows the networks to converge to a robust minimum so that aggressive data augmentation techniques can be applied to expand the limited data fully. In particular, the quaternion-valued QMFL module treats different modalities as components of quaternions to sufficiently learn complementary information among different modalities on the hypercomplex domain while significantly reducing the number of parameters by about 75\%. Main results. Extensive experiments on the dataset BraTS 2020 and BraTS 2019 indicate that QMLS achieves superior results to current popular methods with less computational cost. Significance. We propose a novel algorithm for brain tumor segmentation task that achieves better performance with fewer parameters, which helps the clinical application of automatic brain tumor segmentation.},
	language = {en},
	number = {1},
	urldate = {2024-01-12},
	journal = {Physics in Medicine \& Biology},
	author = {Deng, Zhengnan and Huang, Guoheng and Yuan, Xiaochen and Zhong, Guo and Lin, Tongxu and Pun, Chi-Man and Huang, Zhixin and Liang, Zhixin},
	month = dec,
	year = {2023},
	note = {Publisher: IOP Publishing},
	pages = {015014},
}

@article{huang_gdn-cmcf_2023,
	title = {{GDN}-{CMCF}: {A} {Gated} {Disentangled} {Network} {With} {Cross}-{Modality} {Consensus} {Fusion} for {Multimodal} {Named} {Entity} {Recognition}},
	issn = {2329-924X},
	shorttitle = {{GDN}-{CMCF}},
	url = {https://ieeexplore.ieee.org/abstract/document/10286520},
	doi = {10.1109/TCSS.2023.3323402},
	abstract = {Multimodal named entity recognition (MNER) is a crucial task in social systems of artificial intelligence that requires precise identification of named entities in sentences using both visual and textual information. Previous methods have focused on capturing fine-grained visual features and developing complex fusion procedures. However, these approaches overlook the heterogeneity gap and loss of original modality uniqueness that may occur during fusion, leading to incorrect entity identification. This article proposes a novel approach for MNER called a gated disentangled network with cross-modality consensus fusion (GDN-CMCF) to address the above challenges. Specifically, to eliminate cross-modality variation, we propose a cross-modality consensus fusion module that generates a consensus representation by learning inter-and intramodality interactions with a designed commonality constraint. We then introduce a gated disentanglement module to separate modality-relevant features from support and auxiliary modalities, which further filters out extraneous information while retaining the uniqueness of unimodal features. Experimental results on two real public datasets are provided to verify the effectiveness of our proposed GDN-CMCF. The source code of this article can be found at https://github.com/HaoDavis/ GDN-CMCF.},
	urldate = {2024-01-12},
	journal = {IEEE Transactions on Computational Social Systems},
	author = {Huang, Guoheng and He, Qin and Dai, Zihao and Zhong, Guo and Yuan, Xiaochen and Pun, Chi-Man},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Computational Social Systems},
	pages = {1--11},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/ERHXMP7I/10286520.html:text/html;IEEE Xplore Full Text PDF:/Users/maodou/Zotero/storage/QIN3KAX5/Huang 等 - 2023 - GDN-CMCF A Gated Disentangled Network With Cross-.pdf:application/pdf},
}

@article{wang_qgd-net_2023,
	title = {{QGD}-{Net}: {A} {Lightweight} {Model} {Utilizing} {Pixels} of {Affinity} in {Feature} {Layer} for {Dermoscopic} {Lesion} {Segmentation}},
	volume = {27},
	issn = {2168-2194, 2168-2208},
	shorttitle = {{QGD}-{Net}},
	url = {https://ieeexplore.ieee.org/document/10267979/},
	doi = {10.1109/JBHI.2023.3320953},
	language = {en},
	number = {12},
	urldate = {2024-01-12},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Wang, Jingchao and Huang, Guoheng and Zhong, Guo and Yuan, Xiaochen and Pun, Chi-Man and Deng, Jie},
	month = dec,
	year = {2023},
	pages = {5982--5993},
	file = {Wang 等 - 2023 - QGD-Net A Lightweight Model Utilizing Pixels of A.pdf:/Users/maodou/Zotero/storage/8YIVTBFS/Wang 等 - 2023 - QGD-Net A Lightweight Model Utilizing Pixels of A.pdf:application/pdf},
}

@article{zhang_tampering_2023,
	title = {Tampering localization and self-recovery using block labeling and adaptive significance},
	volume = {226},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417423007303},
	doi = {10.1016/j.eswa.2023.120228},
	abstract = {This paper proposes a scheme for localization and restoration of image tampered regions using block labelling and adaptive significance. To generate the watermark information which includes authentication data and re­ covery data, we propose a block coordinate labelling method, which extracts the exact coordinate position in­ formation of each block, while the recovery data is composed of Block Adaptive Significances (BAS) and bitmaps, which are composed of high and low adaptive significance. To detect the tampered area more effectively, we propose a dual detection approach that combines the block-based labeling (BBL) and pixel-based labeling (PBL). We embed the authentication data into each pixel in the block sequentially and embed the position coordinate information of the block into the whole image in ascending order. The PBL approach can be used to rapidly complete tamper detection when the requirements for PBL are satisfied, whereas the BBL is used to increase the possibility of successfully detecting tampering if the conditions are not satisfied. Furthermore, we propose a block-level partially symmetric mapping and apply it to self-recovery bits in block units, thereby reducing the possibility of recovery bits being lost. The experimental results show that in our scheme, the average precision reaches 86.70\%, which is 4\% higher than the existing results, and the average F1score reaches 92.02\%, which is 2\% higher than the existing results.},
	language = {en},
	urldate = {2024-01-12},
	journal = {Expert Systems with Applications},
	author = {Zhang, Qiyuan and Yuan, Xiaochen and Liu, Tong and Lam, Chan-Tong and Huang, Guoheng and Lin, Di and Li, Ping},
	month = sep,
	year = {2023},
	pages = {120228},
	file = {Zhang 等 - 2023 - Tampering localization and self-recovery using blo.pdf:/Users/maodou/Zotero/storage/HCRJUEF8/Zhang 等 - 2023 - Tampering localization and self-recovery using blo.pdf:application/pdf},
}

@article{hu_learning_2023,
	title = {Learning from {Incorrectness}: {Active} {Learning} with {Negative} {Pre}-training and {Curriculum} {Querying} for {Histological} {Tissue} {Classification}},
	issn = {0278-0062, 1558-254X},
	shorttitle = {Learning from {Incorrectness}},
	url = {https://ieeexplore.ieee.org/document/10244066/},
	doi = {10.1109/TMI.2023.3313509},
	language = {en},
	urldate = {2024-01-12},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Hu, Wentao and Cheng, Lianglun and Huang, Guoheng and Yuan, Xiaochen and Zhong, Guo and Pun, Chi-Man and Zhou, Jian and Cai, Muyan},
	year = {2023},
	pages = {1--1},
	file = {Hu 等 - 2023 - Learning from Incorrectness Active Learning with .pdf:/Users/maodou/Zotero/storage/UDMMVYMC/Hu 等 - 2023 - Learning from Incorrectness Active Learning with .pdf:application/pdf},
}

@article{sun_frrw_2023,
	title = {{FRRW}: {A} feature extraction-based robust and reversible watermarking scheme utilizing zernike moments and histogram shifting},
	volume = {35},
	issn = {13191578},
	shorttitle = {{FRRW}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1319157823002525},
	doi = {10.1016/j.jksuci.2023.101698},
	abstract = {This paper introduces a feature extraction-based approach to ensure both robustness and reversibility of image. Low-order Zernike moments are utilized to embed a robust binary image as a watermark, which is used for information authentication. A reversible watermark is embedded outside the robust watermark regions and is employed for the purpose of restoring the cover image. It uses the combination of histogram shifting and prediction error, which can improve image restoration quality. Steady feature points are extracted in two ways, the speed-up robust features (SURF) algorithm and the oriented fast and rotated brief (ORB) algorithm. After extracting the feature points, the regions are obtained by extending the ﬁnal selected feature points to embed the watermark. Consequently, the presented watermarking technique combines robust and reversible watermarking which has the ability to enhance the invisibility of the watermark and the clarity of image restoration. It is possible to extract the watermark even after an attack has been made on the watermarked image. Or we can recover the original image with no attacks. The results from the experiments indicate that the suggested method is resilient to geometric deformations, involving scaling and rotation, along with typical signal manipulation attacks, including noisebased attacks.},
	language = {en},
	number = {8},
	urldate = {2024-01-12},
	journal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Sun, Ying and Yuan, Xiaochen and Liu, Tong and Huang, Guoheng and Lin, Zhaojun and Li, Jianqing},
	month = sep,
	year = {2023},
	pages = {101698},
	file = {Sun 等 - 2023 - FRRW A feature extraction-based robust and revers.pdf:/Users/maodou/Zotero/storage/9928H2CF/Sun 等 - 2023 - FRRW A feature extraction-based robust and revers.pdf:application/pdf},
}

@article{lin_scdet_2023,
	title = {{SCDet}: decoupling discriminative representation for dark object detection via supervised contrastive learning},
	issn = {1432-2315},
	shorttitle = {{SCDet}},
	url = {https://doi.org/10.1007/s00371-023-03039-x},
	doi = {10.1007/s00371-023-03039-x},
	abstract = {Despite the significant progress made in object detection algorithms, their potential to operate effectively under the low-light environment remains to be fully explored. Recent methods realize dark object detection on the entire representation of dark images; however, they do not further consider the potential entanglement between dark disturbance and discriminative information in dark images, and thus, the learned representation may be sub-optimal. Towards this issue, we propose supervised contrastive detection (SCDet), a novel unified framework to learn the potential composition of dark images, and decouple the discriminative component for facilitating dark object detection. Specifically, we introduce the dense decoupling contrastive (DDC) pretext task to investigate the feature consistency based on a dark transformation, allowing the learned representation to be independent of the potential entanglement to realize decoupling. Moreover, to further drive the decoupled representation to be discriminative instead of a collapse solution for dark object detection, we incorporate the supervision detection task as an extra optimization objective, resulting in the joint optimization pattern. The two tasks are complementary to each other: the DDC task regularizes the detection to learn more decoupling-friendly representation, while the supervision detection task guides the discriminative representation decoupling. As a result, the SCDet achieves dark object detection by decoding the decoupled discriminative representation of dark images. Extensive experiments on four datasets demonstrate the effectiveness of our method in both synthetic and real-world scenarios. Code is available at https://github.com/TxLin7/SCDet.},
	language = {en},
	urldate = {2024-01-12},
	journal = {The Visual Computer},
	author = {Lin, Tongxu and Huang, Guoheng and Yuan, Xiaochen and Zhong, Guo and Huang, Xiaocong and Pun, Chi-Man},
	month = aug,
	year = {2023},
	keywords = {Dark object detection, Low-light environment, Representation decoupling, Supervised contrastive learning},
	file = {Full Text PDF:/Users/maodou/Zotero/storage/S3XV69RT/Lin 等 - 2023 - SCDet decoupling discriminative representation fo.pdf:application/pdf},
}

@article{zhao_spa-net_2023,
	title = {{SPA}-{Net}: {A} {Deep} {Learning} {Approach} {Enhanced} {Using} a {Span}-{Partial} {Structure} and {Attention} {Mechanism} for {Image} {Copy}-{Move} {Forgery} {Detection}},
	volume = {23},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/14/6430},
	doi = {10.3390/s23146430},
	abstract = {With the wide application of visual sensors and development of digital image processing technology, image copy-move forgery detection (CMFD) has become more and more prevalent. Copy-move forgery is copying one or several areas of an image and pasting them into another part of the same image, and CMFD is an efficient means to expose this. There are improper uses of forged images in industry, the military, and daily life. In this paper, we present an efficient end-to-end deep learning approach for CMFD, using a span-partial structure and attention mechanism (SPA-Net). The SPA-Net extracts feature roughly using a pre-processing module and finely extracts deep feature maps using the span-partial structure and attention mechanism as a SPA-net feature extractor module. The span-partial structure is designed to reduce the redundant feature information, while the attention mechanism in the span-partial structure has the advantage of focusing on the tamper region and suppressing the original semantic information. To explore the correlation between high-dimension feature points, a deep feature matching module assists SPA-Net to locate the copy-move areas by computing the similarity of the feature map. A feature upsampling module is employed to upsample the features to their original size and produce a copy-move mask. Furthermore, the training strategy of SPA-Net without pretrained weights has a balance between copy-move and semantic features, and then the module can capture more features of copy-move forgery areas and reduce the confusion from semantic objects. In the experiment, we do not use pretrained weights or models from existing networks such as VGG16, which would bring the limitation of the network paying more attention to objects other than copy-move areas.To deal with this problem, we generated a SPANet-CMFD dataset by applying various processes to the benchmark images from SUN and COCO datasets, and we used existing copy-move forgery datasets, CMH, MICC-F220, MICC-F600, GRIP, Coverage, and parts of USCISI-CMFD, together with our generated SPANet-CMFD dataset, as the training set to train our model. In addition, the SPANet-CMFD dataset could play a big part in forgery detection, such as deepfakes. We employed the CASIA and CoMoFoD datasets as testing datasets to verify the performance of our proposed method. The Precision, Recall, and F1 are calculated to evaluate the CMFD results. Comparison results showed that our model achieved a satisfactory performance on both testing datasets and performed better than the existing methods.},
	number = {14},
	journal = {Sensors},
	author = {Zhao, Kaiqi and Yuan, Xiaochen and Xie, Zhiyao and Xiang, Yan and Huang, Guoheng and Feng, Li},
	year = {2023},
}

@article{lin_improving_2023,
	title = {Improving breast tumor segmentation via shape-wise prior-guided information on cone-beam breast {CT} images},
	volume = {68},
	issn = {0031-9155},
	url = {https://dx.doi.org/10.1088/1361-6560/ace1cf},
	doi = {10.1088/1361-6560/ace1cf},
	abstract = {Objective. Due to the blurry edges and uneven shape of breast tumors, breast tumor segmentation can be a challenging task. Recently, deep convolution networks based approaches achieve satisfying segmentation results. However, the learned shape information of breast tumors might be lost owing to the successive convolution and down-sampling operations, resulting in limited performance. Approach. To this end, we propose a novel shape-guided segmentation (SGS) framework that guides the segmentation networks to be shape-sensitive to breast tumors by prior shape information. Different from usual segmentation networks, we guide the networks to model shape-shared representation with the assumption that shape information of breast tumors can be shared among samples. Specifically, on the one hand, we propose a shape guiding block (SGB) to provide shape guidance through a superpixel pooling-unpooling operation and attention mechanism. On the other hand, we further introduce a shared classification layer (SCL) to avoid feature inconsistency and additional computational costs. As a result, the proposed SGB and SCL can be effortlessly incorporated into mainstream segmentation networks (e.g. UNet) to compose the SGS, facilitating compact shape-friendly representation learning. Main results. Experiments conducted on a private dataset and a public dataset demonstrate the effectiveness of the SGS compared to other advanced methods. Significance. We propose a united framework to encourage existing segmentation networks to improve breast tumor segmentation by prior shape information. The source code will be made available at https://github.com/TxLin7/Shape-Seg.},
	language = {en},
	number = {14},
	urldate = {2024-01-12},
	journal = {Physics in Medicine \& Biology},
	author = {Lin, Tongxu and Lin, Junyu and Huang, Guoheng and Yuan, Xiaochen and Zhong, Guo and Xie, Fenfang and Li, Jiao},
	month = jul,
	year = {2023},
	note = {Publisher: IOP Publishing},
	pages = {145015},
}

@article{yuan_rba-gcn_2023,
	title = {{RBA}-{GCN}: {Relational} {Bilevel} {Aggregation} {Graph} {Convolutional} {Network} for {Emotion} {Recognition}},
	volume = {31},
	issn = {2329-9290, 2329-9304},
	shorttitle = {{RBA}-{GCN}},
	url = {https://ieeexplore.ieee.org/document/10147368/},
	doi = {10.1109/TASLP.2023.3284509},
	language = {en},
	urldate = {2024-01-12},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Yuan, Lin and Huang, Guoheng and Li, Fenghuan and Yuan, Xiaochen and Pun, Chi-Man and Zhong, Guo},
	year = {2023},
	pages = {2325--2337},
	file = {Yuan 等 - 2023 - RBA-GCN Relational Bilevel Aggregation Graph Conv.pdf:/Users/maodou/Zotero/storage/GAPQXIQQ/Yuan 等 - 2023 - RBA-GCN Relational Bilevel Aggregation Graph Conv.pdf:application/pdf},
}

@article{li_mv-cdn_2023,
	title = {{MV}-{CDN}: {Multi}-{Visual} {Collaborative} {Deep} {Network} for {Change} {Detection} of {Double}-{Temporal} {Hyperspectral} {Images}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	shorttitle = {{MV}-{CDN}},
	url = {https://www.mdpi.com/2072-4292/15/11/2834},
	doi = {10.3390/rs15112834},
	abstract = {Since individual neural networks have limited deep expressiveness and effectiveness, many learning frameworks face difficulties in the availability and balance of sample selection. As a result, in change detection, it is difficult to upgrade the hit rate of a high-performance model on both positive and negative pixels. Therefore, supposing that the sacrificed components coincide perfectly with the important evaluation objectives, such as positives, it would lose more than gain. To address this issue, in this paper, we propose a multi-visual collaborative deep network (MV-CDN) served by three collaborative network members that consists of three subdivision approaches, the CDN with one collaborator (CDN-C), CDN with two collaborators (CDN-2C), and CDN with three collaborators (CDN-3C). The purpose of the collaborator is to re-evaluate the feature elements in the network transmission, and thus to translate the group-thinking into a more robust field of vision. We use three sets of public double-temporal hyperspectral images taken by the AVIRIS and HYPERION sensors to show the feasibility of the proposed schema. The comparison results have confirmed that our proposed schema outperforms the existing state-of-the-art algorithms on the three tested datasets, which demonstrates the broad adaptability and progressiveness of the proposal.},
	language = {en},
	number = {11},
	urldate = {2024-01-12},
	journal = {Remote Sensing},
	author = {Li, Jinlong and Yuan, Xiaochen and Li, Jinfeng and Huang, Guoheng and Feng, Li and Zhang, Jing},
	month = jan,
	year = {2023},
	note = {Number: 11
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {changed sensitivity network, collaborative network member, hyperspectral images, multi-visual collaborative deep network (MV-CDN), unchanged sensitivity network},
	pages = {2834},
	file = {Full Text PDF:/Users/maodou/Zotero/storage/NJ2VDQN2/Li 等 - 2023 - MV-CDN Multi-Visual Collaborative Deep Network fo.pdf:application/pdf},
}

@article{liu_paralinguistic_2023,
	title = {Paralinguistic and spectral feature extraction for speech emotion classification using machine learning techniques},
	volume = {2023},
	issn = {1687-4722},
	url = {https://asmp-eurasipjournals.springeropen.com/articles/10.1186/s13636-023-00290-x},
	doi = {10.1186/s13636-023-00290-x},
	abstract = {Abstract
            Emotion plays a dominant role in speech. The same utterance with different emotions can lead to a completely different meaning. The ability to perform various of emotion during speaking is also one of the typical characters of human. In this case, technology trends to develop advanced speech emotion classification algorithms in the demand of enhancing the interaction between computer and human beings. This paper proposes a speech emotion classification approach based on the paralinguistic and spectral features extraction. The Mel-frequency cepstral coefficients (MFCC) are extracted as spectral feature, and openSMILE is employed to extract the paralinguistic feature. The machine learning techniques multi-layer perceptron classifier and support vector machines are respectively applied into the extracted features for the classification of the speech emotions. We have conducted experiments on the Berlin database to evaluate the performance of the proposed approach. Experimental results show that the proposed approach achieves satisfied performances. Comparisons are conducted in clean condition and noisy condition respectively, and the results indicate better performance of the proposed scheme.},
	language = {en},
	number = {1},
	urldate = {2024-01-12},
	journal = {EURASIP Journal on Audio, Speech, and Music Processing},
	author = {Liu, Tong and Yuan, Xiaochen},
	month = may,
	year = {2023},
	pages = {23},
}

@article{li_power_2023,
	title = {Power normalized cepstral robust features of deep neural networks in a cloud computing data privacy protection scheme},
	volume = {518},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231222013741},
	doi = {10.1016/j.neucom.2022.11.001},
	abstract = {Deep Neural Networks (DNNs) have developed rapidly in data privacy protection applications such as medical treatment and ﬁnance. However, DNNs require high-speed and high-memory computers in terms of computation, otherwise training can be very lengthy. Furthermore, DNNs are often not available in resource-constrained mobile devices. Therefore, training and executing DNNs are increasingly using cloud computing. In the paper, the Power Normalized Cepstrum-based Robust Feature Detector (PNCRFD), with deep learning in the cloud computing, is proposed for data privacy protection. The proposed PNC-RFD extracts a speciﬁed number of signal segments of high robustness used to embed and extract various data. For the sake of embedding and extracting the data, a method of information hiding employing Dual-Tree Complex Wavelet Packet Transform (DT CWPT) is therefore presented. The presented scheme simultaneously embeds multiple data into coefﬁcients of the DT CWPT of signal segments. By embedding the data into the orthogonal spaces, the proposed method ensures the independent extraction of the multiple data. In line with the performance analysis, the superiority of the presented scheme is elaborated through making the comparison with the current state-of-the-art methods.},
	language = {en},
	urldate = {2024-01-12},
	journal = {Neurocomputing},
	author = {Li, Mianjie and Tian, Zhihong and Du, Xiaojiang and Yuan, Xiaochen and Shan, Chun and Guizani, Mohsen},
	month = jan,
	year = {2023},
	pages = {165--173},
	file = {Li 等 - 2023 - Power normalized cepstral robust features of deep .pdf:/Users/maodou/Zotero/storage/X2GT7QGH/Li 等 - 2023 - Power normalized cepstral robust features of deep .pdf:application/pdf},
}

@article{zheng_quaternion-valued_2023,
	title = {Quaternion-{Valued} {Correlation} {Learning} for {Few}-{Shot} {Semantic} {Segmentation}},
	volume = {33},
	issn = {1051-8215, 1558-2205},
	url = {https://ieeexplore.ieee.org/document/9954424/},
	doi = {10.1109/TCSVT.2022.3223150},
	abstract = {Few-shot segmentation (FSS) aims to segment unseen classes given only a few annotated samples. Encouraging progress has been made for FSS by leveraging semantic features learned from base classes with sufﬁcient training samples to represent novel classes. The correlation-based methods lack the ability to consider interaction of the two subspace matching scores due to the inherent nature of the real-valued 2D convolutions. In this paper, we introduce a quaternion perspective on correlation learning and propose a novel Quaternion-valued Correlation Learning Network (QCLNet), with the aim to alleviate the computational burden of high-dimensional correlation tensor and explore internal latent interaction between query and support images by leveraging operations deﬁned by the established quaternion algebra. Speciﬁcally, our QCLNet is formulated as a hyper-complex valued network and represents correlation tensors in the quaternion domain, which uses quaternion-valued convolution to explore the external relations of query subspace when considering the hidden relationship of the support sub-dimension in the quaternion space. Extensive experiments on the PASCAL-5i and COCO-20i datasets demonstrate that our method outperforms the existing state-of-the-art methods effectively.},
	language = {en},
	number = {5},
	urldate = {2024-01-12},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {Zheng, Zewen and Huang, Guoheng and Yuan, Xiaochen and Pun, Chi-Man and Liu, Hongrui and Ling, Wing-Kuen},
	month = may,
	year = {2023},
	pages = {2102--2115},
	file = {Zheng 等 - 2023 - Quaternion-Valued Correlation Learning for Few-Sho.pdf:/Users/maodou/Zotero/storage/6TSPT4CU/Zheng 等 - 2023 - Quaternion-Valued Correlation Learning for Few-Sho.pdf:application/pdf},
}
